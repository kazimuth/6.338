#+TITLE: 18.337 homework 2
#+AUTHOR: James Gilles
#+EMAIL: jhgilles@mit.edu
#+DATE: 7 November 2019
#+OPTIONS: tex:t latex:t
#+STARTUP: latexpreview

#+LATEX_CLASS: tufte-handout
#+LATEX_HEADER: \usepackage{ifluatex, ifxetex}
#+LATEX_HEADER: %Next block avoids bug, from http://tex.stackexchange.com/a/200725/1913
#+LATEX_HEADER: \ifx\ifxetex\ifluatex\else
#+LATEX_HEADER:   \newcommand{\textls}[2][5]{%
#+LATEX_HEADER:     \begingroup\addfontfeatures{LetterSpace=#1}#2\endgroup
#+LATEX_HEADER:   }
#+LATEX_HEADER:   \renewcommand{\allcapsspacing}[1]{\textls[15]{#1}}
#+LATEX_HEADER:   \renewcommand{\smallcapsspacing}[1]{\textls[10]{#1}}
#+LATEX_HEADER:   \renewcommand{\allcaps}[1]{\textls[15]{\MakeTextUppercase{#1}}}
#+LATEX_HEADER:   \renewcommand{\smallcaps}[1]{\smallcapsspacing{\scshape\MakeTextLowercase{#1}}}
#+LATEX_HEADER:   \renewcommand{\textsc}[1]{\smallcapsspacing{\textsmallcaps{#1}}}
#+LATEX_HEADER:   % shove everything else in here so we don't mess with emacs latexpreview, which doesn't use lualatex
#+LATEX_HEADER:   \usepackage{fontspec}
#+LATEX_HEADER:   \setmainfont{ETBookOT}
#+LATEX_HEADER:   \setmonofont[Scale=0.8]{Fantasque Sans Mono}
#+LATEX_HEADER:   \renewcommand{\contentsname}{Contents}
#+LATEX_HEADER:   \titleformat{\chapter}%
#+LATEX_HEADER:     [display]% shape
#+LATEX_HEADER:     {\relax\ifthenelse{\NOT\boolean{@tufte@symmetric}}{\begin{fullwidth}}{}}% format applied to label+text
#+LATEX_HEADER:     {\huge\thechapter}% label
#+LATEX_HEADER:     {0pt}% horizontal separation between label and title body
#+LATEX_HEADER:     {\huge\rmfamily}% before the title body
#+LATEX_HEADER:     [\ifthenelse{\NOT\boolean{@tufte@symmetric}}{\end{fullwidth}}{}]% after the title body
#+LATEX_HEADER:   \titleformat{\section}%
#+LATEX_HEADER:     [hang]% shape
#+LATEX_HEADER:     {\normalfont\Large}% format applied to label+text
#+LATEX_HEADER:     {\thesection}% label
#+LATEX_HEADER:     {1em}% horizontal separation between label and title body
#+LATEX_HEADER:     {}% before the title body
#+LATEX_HEADER:     []% after the title body
#+LATEX_HEADER:   \titleformat{\subsection}%
#+LATEX_HEADER:     [hang]% shape
#+LATEX_HEADER:     {\normalfont\large\itshape}% format applied to label+text
#+LATEX_HEADER:     {\thesubsection}% label
#+LATEX_HEADER:     {1em}% horizontal separation between label and title body
#+LATEX_HEADER:     {}% before the title body
#+LATEX_HEADER:     []% after the title body
#+LATEX_HEADER:   \renewcommand{\maketitle}{%
#+LATEX_HEADER:     \begingroup
#+LATEX_HEADER:       \setlength{\parindent}{0pt}%
#+LATEX_HEADER:       \setlength{\parskip}{4pt}%
#+LATEX_HEADER:       \LARGE\scshape\plaintitle\par
#+LATEX_HEADER:       \Large\itshape\plainauthor\par
#+LATEX_HEADER:       \Large\itshape\thedate\par
#+LATEX_HEADER:     \endgroup
#+LATEX_HEADER:     %\thispagestyle{plain}% suppress the running head
#+LATEX_HEADER:     %\tuftebreak
#+LATEX_HEADER:     %\@afterindentfalse\@afterheading% suppress indentation of the next paragraph
#+LATEX_HEADER:   }
#+LATEX_HEADER:   \usepackage{graphicx}
#+LATEX_HEADER: \fi

#+LATEX_HEADER: \newcommand{\xv}[0]{\mathbf{x}}
#+LATEX_HEADER: \newcommand{\yv}[0]{\mathbf{y}}
#+LATEX_HEADER: \newcommand{\zv}[0]{\mathbf{z}}
#+LATEX_HEADER: \newcommand{\fv}[0]{\mathbf{f}}
#+LATEX_HEADER: \newcommand{\J}[0]{\mathbf{J}}
#+LATEX_HEADER: \newcommand{\gv}[0]{\mathbf{g}}
#+LATEX_HEADER: \newcommand{\hv}[0]{\mathbf{h}}
#+LATEX_HEADER: \newcommand{\sv}[0]{\mathbf{s}}
#+LATEX_HEADER: \newcommand{\uv}[0]{\mathbf{u}}
#+LATEX_HEADER: \newcommand{\pv}[0]{\mathbf{p}}
#+LATEX_HEADER: \newcommand{\kv}[0]{\mathbf{k}}
#+LATEX_HEADER: \newcommand{\hxo}[0]{\mathbf{h}_0}

#+LATEX_HEADER: \usepackage{mathtools}
#+LATEX_HEADER:
#+LATEX_HEADER: \DeclarePairedDelimiter\abs{\lvert}{\rvert}%
#+LATEX_HEADER: \DeclarePairedDelimiter\norm{\lVert}{\rVert}%
#+LATEX_HEADER:
#+LATEX_HEADER: % Swap the definition of \abs* and \norm*, so that \abs
#+LATEX_HEADER: % and \norm resizes the size of the brackets, and the
#+LATEX_HEADER: % starred version does not.
#+LATEX_HEADER: \makeatletter
#+LATEX_HEADER: \let\oldabs\abs
#+LATEX_HEADER: \def\abs{\@ifstar{\oldabs}{\oldabs*}}
#+LATEX_HEADER: %
#+LATEX_HEADER: \let\oldnorm\norm
#+LATEX_HEADER: \def\norm{\@ifstar{\oldnorm}{\oldnorm*}}
#+LATEX_HEADER: \makeatother

#+LATEX_HEADER: \newcommand*{\approxident}{%
#+LATEX_HEADER: \mathrel{\vcenter{\offinterlineskip
#+LATEX_HEADER: \hbox{$\sim$}\vskip-.35ex\hbox{$\sim$}\vskip}}}

#+BEGIN_SRC julia :session jl :async yes :exports both
using StaticArrays
using LinearAlgebra
using Plots
#using DifferentialEquations
#using ForwardDiff
#using Zygote
#using SymPy
#+END_SRC

#+RESULTS:

* problem 1: parameter estimation
** part 1: dormand-prince / lotka-volterra
The Lotka-Volterra equations are written:

\begin{align*}
\frac{dx}{dt} &= \alpha x - \beta x y\\
\frac{dy}{dt} &= - \gamma y + \delta x y\\
\end{align*}

We can define a julia function:

#+BEGIN_SRC julia :session jl :async yes :exports both
function lotka_volterra(_t, u; p = [1.5, 1.0, 3.0, 1.0])
    x = u[1]
    y = u[2]

    α = p[1]
    β = p[2]
    γ = p[3]
    δ = p[4]

    dx = α*x - β*x*y
    dy = - γ*y + δ*x*y
    @SVector [dx, dy]
end

start = @SVector [1.0, 1.0]
lotka_volterra(0.0, start)
#+END_SRC

#+RESULTS:
: 2-element SArray{Tuple{2},Float64,1,2} with indices SOneTo(2):
:   0.5
:  -2.0

The general form of Runge-Kutta methods is:

$$\uv_{n+1} = \uv_n + \Delta t \sum_{i} b_i \kv_i$$

where

\begin{align*}
 \kv_1 & = f(t_n, \uv_n), \\
 \kv_2 & = f(t_n+c_2\Delta t, \uv_n+\Delta t(a_{21}\kv_1)), \\
 \kv_3 & = f(t_n+c_3\Delta t, \uv_n+\Delta t(a_{31}\kv_1+a_{32}\kv_2)), \\
     & \ \ \vdots \\
 \kv_s & = f(t_n+c_s\Delta t, \uv_n+\Delta t(a_{s1}\kv_1+a_{s2}\kv_2+\cdots+a_{s,s-1}\kv_{s-1})).
\end{align*}

Note: don't confuse this $\yv$ with the $y$ in lotka-volterra, $\yv$ encompasses both $y$ and $x$.

We can define a julia macro which, given a Butcher tableau, creates a function defining the corresponding runge-kutta method:

#+BEGIN_SRC julia :session jl :async yes :exports both
function runge_kutta_step_template(a, b, c, name; evals=size(a)[1])
    n = size(a)[1]
    @assert size(a)[2] == n
    @assert size(b)[1] == n
    @assert size(c)[1] == n
    @assert c[1] == 0
    @assert all(diag(a) .== 0)
    @assert all(abs.(sum(a; dims=2) - c) .< .000001)

    ks = [Symbol("k$i") for i in 1:n]

    lines = []
    for i in 1:evals
        if i == 1
            t = :(t)
            u = :(u)
        else
            t = :(t + $(c[i]) * dt)
            u_shifts = [:($(a[i,j]) * $(ks[j])) for j in 1:(i-1)]
            u = :(u + dt * (+($(u_shifts...))))
        end
        line = :($(ks[i]) = f($t, $u))

        push!(lines, line)
    end
    body = Expr(:block, lines...)
    result_terms = [:($(b[i]) * $(ks[i])) for i in 1:evals]
    name = Symbol(name)
    :(function $name(f, t, u; dt=0.25)
            $body
            u + dt * (+($(result_terms...)))
      end)
end
#+END_SRC

#+RESULTS:
: runge_kutta_step_template (generic function with 1 method)

(Note: this isn't actually a ~macro~ because it's annoying to pass
matrices into those.)

We can try applying this to the euler method:

#+BEGIN_SRC julia :session jl :async yes :exports both
euler_step_template = runge_kutta_step_template(zeros(1,1), [1.0], [0.0], "euler_step")
println("template: \n", euler_step_template)
eval(euler_step_template)
println("evaluate: \n", euler_step((t, v) -> 1.0, 1.0, 1.0; dt=0.25))
#+END_SRC

#+RESULTS:
#+begin_example
template:
function euler_step(f, t, u; dt=0.25)
    #= In[22]:30 =#
    begin
        k1 = f(t, u)
    end
    #= In[22]:31 =#
    u + dt * +(1.0k1)
end
evaluate:
1.25
#+end_example

Looks good.

Now, let's try the full Dormand-Prince tableau.

#+BEGIN_SRC julia :session jl :async yes :exports both
a = [0 0 0 0 0 0 0;
     (1/5.) (0) (0) (0) (0) (0) (0);
     (3/40.) (9/40.) (0) (0) (0) (0) (0);
     (44/45.) (-56/15.) (32/9.) (0) (0) (0) (0);
     (19372/6561.0) (-25360/2187.) (64448/6561.0) (-212/729.0) (0) (0) (0);
     (9017/3168.0) (-355/33.0) (46732/5247.0) (49/176.0) (-5103/18656.) (0) (0);
     (35/384.0) (0) (500/1113.0) (125/192.) (-2187/6784.) (11/84.) (0)]

b = [35/384,   0,   500/1113,   125/192,   (-2187/6784),   11/84,   0]
c = [0., 1/5., 3/10., 4/5., 8/9., 1., 1.]
dormand_prince_step_template = runge_kutta_step_template(a, b, c, "dormand_prince_step", evals=6)
println("template:\n", dormand_prince_step_template)
eval(dormand_prince_step_template)
println("evaluate:\n", dormand_prince_step((t, v) -> 1.0, 1.0, 1.0; dt=0.25))
#+END_SRC

#+RESULTS:
#+begin_example
template:
function dormand_prince_step(f, t, u; dt=0.25)
    #= In[3]:30 =#
    begin
        k1 = f(t, u)
        k2 = f(t + 0.2dt, u + dt * +(0.2k1))
        k3 = f(t + 0.3dt, u + dt * (0.075k1 + 0.225k2))
        k4 = f(t + 0.8dt, u + dt * (0.9777777777777777k1 + -3.7333333333333334k2 + 3.5555555555555554k3))
        k5 = f(t + 0.8888888888888888dt, u + dt * (2.9525986892242035k1 + -11.595793324188385k2 + 9.822892851699436k3 + -0.2908093278463649k4))
        k6 = f(t + 1.0dt, u + dt * (2.8462752525252526k1 + -10.757575757575758k2 + 8.906422717743473k3 + 0.2784090909090909k4 + -0.2735313036020583k5))
    end
    #= In[3]:31 =#
    u + dt * (0.09114583333333333k1 + 0.0k2 + 0.44923629829290207k3 + 0.6510416666666666k4 + -0.322376179245283k5 + 0.13095238095238096k6)
end
evaluate:
1.25
#+end_example

Very nice.

Now we can solve lotka-volterra:

#+BEGIN_SRC julia :session jl :async yes :exports both
function solve(f, u0 :: T; dt=0.25, tmin=0.0, tmax=10.0, step=dormand_prince_step) where {T}
    outputs = T[]
    u = u0
    domain = tmin:dt:tmax
    for t in domain
        push!(outputs, u)
        u = step(f, t, u, dt=dt)
    end
    (domain, outputs)
end
#+END_SRC

#+RESULTS:
: solve (generic function with 1 method)

#+BEGIN_SRC julia :session jl :async yes :exports both
ts, us = solve(lotka_volterra, start, dt=0.25, tmin=0.0, tmax=10.0)
us = hcat([[u[i] for u in us] for i in 1:2]...)
plot(ts, us, format=:png, dpi=200, labels=["x", "y"])
#+END_SRC

#+RESULTS:
[[file:./.ob-jupyter/b27be8bcde0ff347ce1871cc1ed5426c5cf57422.png]]


And, for comparison, a plot of the Euler solution with a much smaller step
size:
#+BEGIN_SRC julia :session jl :async yes :exports both
ts_, us_ = solve(lotka_volterra, start, dt=0.01, tmin=0.0, tmax=10.0, step=euler_step)
us_ = hcat([[u[i] for u in us_] for i in 1:2]...)
plot(ts_, us_, format=:png, dpi=200, labels=["x", "y"])
#+END_SRC

#+RESULTS:
[[file:./.ob-jupyter/dc7fae37e0dfe8d7652748ee8251f0030fd7b5cd.png]]

Pretty close!

** part 2: forward sensitivity

   We want to compute $\frac{\partial \uv}{\partial \pv}|_t$, the sensitivity of the solution to the parameters at some time $t$.
   (Note that $\frac{\partial \uv}{\partial \pv}$ is a 2-by-4 matrix in the case of the lotka-volterra equations.)

   We have:

   $$\frac{\partial}{\partial t}\frac{\partial \uv}{\partial \pv}
   =\frac{\partial \fv}{\partial \uv}\frac{\partial \uv}{\partial \pv}+\frac{\partial \fv}{\partial \pv}$$

   So we have a (matrix) differential equation in $\frac{\partial \uv}{\partial \pv}$, which we can integrate along with $\uv$ in our solver.

   m rows, n cols

   Now we have:

   $$\frac{\partial \fv}{\partial \uv}
   =\left(\begin{array}{cccc}
     \frac{\partial f_{1}}{\partial u_{1}} & \frac{\partial f_{1}}{\partial u_{2}} & \cdots & \frac{\partial f_{1}}{\partial u_{s}}\\
     \frac{\partial f_{2}}{\partial u_{1}} & \frac{\partial f_{2}}{\partial u_{2}} & \cdots & \frac{\partial f_{2}}{\partial u_{s}}\\
     \cdots & \cdots & \cdots & \cdots\\
     \frac{\partial f_{s}}{\partial u_{1}} & \frac{\partial f_{s}}{\partial u_{2}} & \cdots & \frac{\partial f_{s}}{\partial u_{s}}
   \end{array}\right)$$

   $$\frac{\partial \fv}{\partial \pv}
   =\left(\begin{array}{cccc}
     \frac{\partial f_{1}}{\partial p_{1}} & \frac{\partial f_{1}}{\partial p_{2}} & \cdots & \frac{\partial f_{1}}{\partial p_{s}}\\
     \frac{\partial f_{2}}{\partial p_{1}} & \frac{\partial f_{2}}{\partial p_{2}} & \cdots & \frac{\partial f_{2}}{\partial p_{s}}\\
     \cdots & \cdots & \cdots & \cdots\\
     \frac{\partial f_{s}}{\partial p_{1}} & \frac{\partial f_{s}}{\partial p_{2}} & \cdots & \frac{\partial f_{s}}{\partial p_{s}}
   \end{array}\right)$$

   Plugging in:

   $$\begin{align*}
   \frac{dx}{dt} &= \alpha x - \beta x y\\
   \frac{dy}{dt} &= - \gamma y + \delta x y\\
   \end{align*}$$

   Gives:

   $$\begin{align*}\frac{\partial \fv}{\partial \uv}&=\left(\begin{array}{cc}
     \frac{\partial }{\partial x} (\alpha x - \beta x y) & \frac{\partial}{\partial y} (\alpha x - \beta x y) \\
     \frac{\partial }{\partial x} (- \gamma y + \delta x y) & \frac{\partial}{\partial y} (- \gamma y + \delta x y) \\
   \end{array}\right)\\
   &=\left(\begin{array}{cc}
     \alpha - \beta y & -\beta x \\
     -\delta y       & -\gamma y + \delta x \\
   \end{array}\right)\end{align*}$$

   and:

   $$\begin{align*}\frac{\partial \fv}{\partial \pv} &=\left(\begin{array}{cccc}
   \frac{\partial }{\partial \alpha} (\alpha x - \beta x y) & \frac{\partial }{\partial \beta} (\alpha x - \beta x y) &
   \frac{\partial }{\partial \gamma} (\alpha x - \beta x y) & \frac{\partial }{\partial \delta} (\alpha x - \beta x y)\\
   \frac{\partial }{\partial \alpha} (-\gamma y + \delta x y) & \frac{\partial }{\partial \beta} (-\gamma y + \delta x y) &
   \frac{\partial }{\partial \gamma} (-\gamma y + \delta x y) & \frac{\partial }{\partial \delta} (-\gamma y + \delta x y)\\
   \end{array}\right)\\
   &=\left(\begin{array}{cccc}
   x & x y & 0 & 0 \\
   0 & 0 & -y & xy \\
   \end{array}\right)\end{align*}$$

   Great. Now, let's define some functions to wrap this sensitivity matrix into / out of a vector:

#+BEGIN_SRC julia :session jl :async yes :exports both
function wrap_sensitivities(u, s)
    return vcat(u, reshape(s, 8))
end
function unwrap_sensitivities(us)
    u = us[1:2]
    s = reshape(us[3:10], (2, 4))
    u, s
end
u = [1., 2]
s = [1. 2 3 4; 5 6 7 8]
us = wrap_sensitivities(u, s)
u_, s_ = unwrap_sensitivities(us)

@assert u == u_ && s == s_
#+END_SRC

#+RESULTS:

   And a function to operate on those vectors:

#+BEGIN_SRC julia :session jl :async yes :exports both
function lotka_volterra_sens(_t, us, p)
    u, s = unwrap_sensitivities(us)

    x = u[1]
    y = u[2]

    α = p[1]
    β = p[2]
    γ = p[3]
    δ = p[4]

    dx = α*x - β*x*y
    dy = - γ*y + δ*x*y

    du = @SVector [dx, dy]

    dfdu = @SMatrix [(α - β * y) (-β * x); (-δ * y) (-γ * y + δ * x)]
    dfdp = @SMatrix [x (x*y) 0 0; 0 0 (-y) (x*y)]

    ds = dfdu * s + dfdp

    wrap_sensitivities(du, ds)
end
#+END_SRC

#+RESULTS:
: lotka_volterra_sens (generic function with 2 methods)

   Now we can solve for $\uv$, along with the sensitivities:

#+BEGIN_SRC julia :session jl :async yes :exports both
start_sensitivities = @SMatrix [0. 0 0 0; 0 0 0 0]
start_ = wrap_sensitivities(start, start_sensitivities)
p = @SVector [1.5, 1.0, 3.0, 1.0]

ts, us = solve((t, u) -> lotka_volterra_sens(t, u, p), start_, dt=0.25, tmin=0.0, tmax=10.0)
xy = hcat([[u[i] for u in us] for i in 1:2]...)

plot(ts, xy, format=:png, dpi=200, labels=["x", "y"])
#+END_SRC

#+RESULTS:
[[file:./.ob-jupyter/b27be8bcde0ff347ce1871cc1ed5426c5cf57422.png]]

#+BEGIN_SRC julia :session jl :async yes :exports both
u_names = ["x", "y"]
p_names = ["alpha", "beta", "gamma", "delta"]

ss = hcat([[unwrap_sensitivities(u)[2][i,j] for u in us] for i in 1:2 for j in 1:4]...)
labels = ["d$(u_names[i])/d$(p_names[j])" for i in 1:2 for j in 1:4]
plot(ts, sign.(ss) .* log.(abs.(ss)), format=:png, dpi=200, labels=labels)
#+END_SRC

#+RESULTS:
[[file:./.ob-jupyter/fa5f1878f3384cf701caf0c986da200e576efdd8.png]]

We can compare this to the results found by ~ForwardDiff~:

#+BEGIN_SRC julia :session jl :async yes :exports both
using ForwardDiff

function solve_p(p)
    solve((t, u) -> lotka_volterra(t, u, p=p), start, dt=0.25, tmin=0.0, tmax=10.0)
end

ss_ = ForwardDiff.jacobian(solve_p, p)
#+END_SRC

#+RESULTS:
:RESULTS:
# [goto error]
#+begin_example
MethodError: no method matching Float64(::ForwardDiff.Dual{ForwardDiff.Tag{typeof(solve_p),Float64},Float64,4})
Closest candidates are:
  Float64(::Real, !Matched::RoundingMode) where T<:AbstractFloat at rounding.jl:194
  Float64(::T<:Number) where T<:Number at boot.jl:718
  Float64(!Matched::Int8) at float.jl:60
  ...

Stacktrace:
 [1] convert(::Type{Float64}, ::ForwardDiff.Dual{ForwardDiff.Tag{typeof(solve_p),Float64},Float64,4}) at ./number.jl:7
 [2] macro expansion at /home/radical/.julia/packages/StaticArrays/3KEjZ/src/util.jl:11 [inlined]
 [3] convert_ntuple at /home/radical/.julia/packages/StaticArrays/3KEjZ/src/util.jl:8 [inlined]
 [4] SArray{Tuple{2},Float64,1,2}(::Tuple{ForwardDiff.Dual{ForwardDiff.Tag{typeof(solve_p),Float64},Float64,4},ForwardDiff.Dual{ForwardDiff.Tag{typeof(solve_p),Float64},Float64,4}}) at /home/radical/.julia/packages/StaticArrays/3KEjZ/src/SArray.jl:28
 [5] convert at /home/radical/.julia/packages/StaticArrays/3KEjZ/src/convert.jl:10 [inlined]
 [6] push!(::Array{SArray{Tuple{2},Float64,1,2},1}, ::SArray{Tuple{2},ForwardDiff.Dual{ForwardDiff.Tag{typeof(solve_p),Float64},Float64,4},1,2}) at ./array.jl:852
 [7] #solve#16(::Float64, ::Float64, ::Float64, ::Function, ::typeof(solve), ::Function, ::SArray{Tuple{2},Float64,1,2}) at ./In[5]:6
 [8] (::getfield(Main, Symbol("#kw##solve")))(::NamedTuple{(:dt, :tmin, :tmax),Tuple{Float64,Float64,Float64}}, ::typeof(solve), ::Function, ::SArray{Tuple{2},Float64,1,2}) at ./none:0
 [9] solve_p(::SArray{Tuple{4},ForwardDiff.Dual{ForwardDiff.Tag{typeof(solve_p),Float64},Float64,4},1,4}) at ./In[16]:4
 [10] static_dual_eval(::Type{ForwardDiff.Tag{typeof(solve_p),Float64}}, ::typeof(solve_p), ::SArray{Tuple{4},Float64,1,4}) at /home/radical/.julia/packages/ForwardDiff/N0wMF/src/apiutils.jl:32
 [11] vector_mode_jacobian(::Function, ::SArray{Tuple{4},Float64,1,4}) at /home/radical/.julia/packages/ForwardDiff/N0wMF/src/jacobian.jl:173
 [12] jacobian(::Function, ::SArray{Tuple{4},Float64,1,4}) at /home/radical/.julia/packages/ForwardDiff/N0wMF/src/jacobian.jl:81
 [13] top-level scope at In[16]:6
#+end_example
:END:

** part 3: parameter estimation
