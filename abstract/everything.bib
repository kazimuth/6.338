@ARTICLE{HighFreqGeneralization,
       author = {{Wang}, Haohan and {Wu}, Xindi and {Yin}, Pengcheng and {Xing}, Eric P.},
        title = "{High Frequency Component Helps Explain the Generalization of Convolutional Neural Networks}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
         year = "2019",
        month = "May",
          eid = {arXiv:1905.13545},
        pages = {arXiv:1905.13545},
archivePrefix = {arXiv},
       eprint = {1905.13545},
 primaryClass = {cs.CV},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2019arXiv190513545W},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{TransferPerturb,
       author = {{Naseer}, Muzammal and {Khan}, Salman H. and {Khan}, Harris and
         {Shahbaz Khan}, Fahad and {Porikli}, Fatih},
        title = "{Cross-Domain Transferability of Adversarial Perturbations}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Computer Vision and Pattern Recognition},
         year = "2019",
        month = "May",
          eid = {arXiv:1905.11736},
        pages = {arXiv:1905.11736},
archivePrefix = {arXiv},
       eprint = {1905.11736},
 primaryClass = {cs.CV},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2019arXiv190511736N},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{NotBugsFeatures,
       author = {{Ilyas}, Andrew and {Santurkar}, Shibani and {Tsipras}, Dimitris and
         {Engstrom}, Logan and {Tran}, Brandon and {Madry}, Aleksander},
        title = "{Adversarial Examples Are Not Bugs, They Are Features}",
      journal = {arXiv e-prints},
     keywords = {Statistics - Machine Learning, Computer Science - Cryptography and Security, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
         year = "2019",
        month = "May",
          eid = {arXiv:1905.02175},
        pages = {arXiv:1905.02175},
archivePrefix = {arXiv},
       eprint = {1905.02175},
 primaryClass = {stat.ML},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2019arXiv190502175I},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{DefensiveQuantization,
       author = {{Lin}, Ji and {Gan}, Chuang and {Han}, Song},
        title = "{Defensive Quantization: When Efficiency Meets Robustness}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Statistics - Machine Learning},
         year = "2019",
        month = "Apr",
          eid = {arXiv:1904.08444},
        pages = {arXiv:1904.08444},
archivePrefix = {arXiv},
       eprint = {1904.08444},
 primaryClass = {cs.LG},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2019arXiv190408444L},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{AdvTimeSeries,
       author = {{Ismail Fawaz}, Hassan and {Forestier}, Germain and {Weber}, Jonathan and
         {Idoumghar}, Lhassane and {Muller}, Pierre-Alain},
        title = "{Adversarial Attacks on Deep Neural Networks for Time Series Classification}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Machine Learning, Computer Science - Cryptography and Security, Statistics - Machine Learning},
         year = "2019",
        month = "Mar",
          eid = {arXiv:1903.07054},
        pages = {arXiv:1903.07054},
archivePrefix = {arXiv},
       eprint = {1903.07054},
 primaryClass = {cs.LG},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2019arXiv190307054I},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{TinySubspace,
       author = {{Gur-Ari}, Guy and {Roberts}, Daniel A. and {Dyer}, Ethan},
        title = "{Gradient Descent Happens in a Tiny Subspace}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Statistics - Machine Learning},
         year = "2018",
        month = "Dec",
          eid = {arXiv:1812.04754},
        pages = {arXiv:1812.04754},
archivePrefix = {arXiv},
       eprint = {1812.04754},
 primaryClass = {cs.LG},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2018arXiv181204754G},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{MeshAdv,
       author = {{Xiao}, Chaowei and {Yang}, Dawei and {Li}, Bo and {Deng}, Jia and
         {Liu}, Mingyan},
        title = "{MeshAdv: Adversarial Meshes for Visual Recognition}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Cryptography and Security, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning},
         year = "2018",
        month = "Oct",
          eid = {arXiv:1810.05206},
        pages = {arXiv:1810.05206},
archivePrefix = {arXiv},
       eprint = {1810.05206},
 primaryClass = {cs.CR},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2018arXiv181005206X},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{ToCompressOrnot,
       author = {{Zhao}, Yiren and {Shumailov}, Ilia and {Mullins}, Robert and
         {Anderson}, Ross},
        title = "{To compress or not to compress: Understanding the Interactions between Adversarial Attacks and Neural Network Compression}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Cryptography and Security, Computer Science - Machine Learning},
         year = "2018",
        month = "Sep",
          eid = {arXiv:1810.00208},
        pages = {arXiv:1810.00208},
archivePrefix = {arXiv},
       eprint = {1810.00208},
 primaryClass = {cs.CR},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2018arXiv181000208Z},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{RobustnessVsAccuracy,
       author = {{Tsipras}, Dimitris and {Santurkar}, Shibani and {Engstrom}, Logan and
         {Turner}, Alexander and {Madry}, Aleksander},
        title = "{Robustness May Be at Odds with Accuracy}",
      journal = {arXiv e-prints},
     keywords = {Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing},
         year = "2018",
        month = "May",
          eid = {arXiv:1805.12152},
        pages = {arXiv:1805.12152},
archivePrefix = {arXiv},
       eprint = {1805.12152},
 primaryClass = {stat.ML},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2018arXiv180512152T},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{MagnetVsL1,
       author = {{Lu}, Pei-Hsuan and {Chen}, Pin-Yu and {Chen}, Kang-Cheng and
         {Yu}, Chia-Mu},
        title = "{On the Limitation of MagNet Defense against $L_1$-based Adversarial Examples}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Cryptography and Security, Computer Science - Machine Learning, Statistics - Machine Learning},
         year = "2018",
        month = "Apr",
          eid = {arXiv:1805.00310},
        pages = {arXiv:1805.00310},
archivePrefix = {arXiv},
       eprint = {1805.00310},
 primaryClass = {cs.CV},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2018arXiv180500310L},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{BypassingFeatureSqueezing,
       author = {{Sharma}, Yash and {Chen}, Pin-Yu},
        title = "{Bypassing Feature Squeezing by Increasing Adversary Strength}",
      journal = {arXiv e-prints},
     keywords = {Statistics - Machine Learning, Computer Science - Machine Learning},
         year = "2018",
        month = "Mar",
          eid = {arXiv:1803.09868},
        pages = {arXiv:1803.09868},
archivePrefix = {arXiv},
       eprint = {1803.09868},
 primaryClass = {stat.ML},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2018arXiv180309868S},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{LogitPairing,
       author = {{Kannan}, Harini and {Kurakin}, Alexey and {Goodfellow}, Ian},
        title = "{Adversarial Logit Pairing}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
         year = "2018",
        month = "Mar",
          eid = {arXiv:1803.06373},
        pages = {arXiv:1803.06373},
archivePrefix = {arXiv},
       eprint = {1803.06373},
 primaryClass = {cs.LG},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2018arXiv180306373K},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{ContrastiveExplanations,
       author = {{Dhurandhar}, Amit and {Chen}, Pin-Yu and {Luss}, Ronny and
         {Tu}, Chun-Chen and {Ting}, Paishun and {Shanmugam}, Karthikeyan and
         {Das}, Payel},
        title = "{Explanations based on the Missing: Towards Contrastive Explanations with Pertinent Negatives}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
         year = "2018",
        month = "Feb",
          eid = {arXiv:1802.07623},
        pages = {arXiv:1802.07623},
archivePrefix = {arXiv},
       eprint = {1802.07623},
 primaryClass = {cs.AI},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2018arXiv180207623D},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{ElasticNetAttacks,
       author = {{Chen}, Pin-Yu and {Sharma}, Yash and {Zhang}, Huan and {Yi}, Jinfeng and
         {Hsieh}, Cho-Jui},
        title = "{EAD: Elastic-Net Attacks to Deep Neural Networks via Adversarial Examples}",
      journal = {arXiv e-prints},
     keywords = {Statistics - Machine Learning, Computer Science - Cryptography and Security, Computer Science - Machine Learning},
         year = "2017",
        month = "Sep",
          eid = {arXiv:1709.04114},
        pages = {arXiv:1709.04114},
archivePrefix = {arXiv},
       eprint = {1709.04114},
 primaryClass = {stat.ML},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2017arXiv170904114C},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{TowardsResistantAdversarial,
       author = {{Madry}, Aleksander and {Makelov}, Aleksandar and {Schmidt}, Ludwig and
         {Tsipras}, Dimitris and {Vladu}, Adrian},
        title = "{Towards Deep Learning Models Resistant to Adversarial Attacks}",
      journal = {arXiv e-prints},
     keywords = {Statistics - Machine Learning, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing},
         year = "2017",
        month = "Jun",
          eid = {arXiv:1706.06083},
        pages = {arXiv:1706.06083},
archivePrefix = {arXiv},
       eprint = {1706.06083},
 primaryClass = {stat.ML},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2017arXiv170606083M},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{EvaluatingRobustness,
       author = {{Carlini}, Nicholas and {Wagner}, David},
        title = "{Towards Evaluating the Robustness of Neural Networks}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Cryptography and Security, Computer Science - Computer Vision and Pattern Recognition},
         year = "2016",
        month = "Aug",
          eid = {arXiv:1608.04644},
        pages = {arXiv:1608.04644},
archivePrefix = {arXiv},
       eprint = {1608.04644},
 primaryClass = {cs.CR},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2016arXiv160804644C},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{LimitationsDLAdversarial,
       author = {{Papernot}, Nicolas and {McDaniel}, Patrick and {Jha}, Somesh and
         {Fredrikson}, Matt and {Berkay Celik}, Z. and {Swami}, Ananthram},
        title = "{The Limitations of Deep Learning in Adversarial Settings}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Cryptography and Security, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning},
         year = "2015",
        month = "Nov",
          eid = {arXiv:1511.07528},
        pages = {arXiv:1511.07528},
archivePrefix = {arXiv},
       eprint = {1511.07528},
 primaryClass = {cs.CR},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2015arXiv151107528P},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{IntriguingProperties,
       author = {{Szegedy}, Christian and {Zaremba}, Wojciech and {Sutskever}, Ilya and
         {Bruna}, Joan and {Erhan}, Dumitru and {Goodfellow}, Ian and
         {Fergus}, Rob},
        title = "{Intriguing properties of neural networks}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing},
         year = "2013",
        month = "Dec",
          eid = {arXiv:1312.6199},
        pages = {arXiv:1312.6199},
archivePrefix = {arXiv},
       eprint = {1312.6199},
 primaryClass = {cs.CV},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2013arXiv1312.6199S},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{DissectingPruned,
       author = {{Frankle}, Jonathan and {Bau}, David},
        title = "{Dissecting Pruned Neural Networks}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning},
         year = "2019",
        month = "Jun",
          eid = {arXiv:1907.00262},
        pages = {arXiv:1907.00262},
archivePrefix = {arXiv},
       eprint = {1907.00262},
 primaryClass = {cs.LG},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2019arXiv190700262F},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{FreeAdvTraining,
       author = {{Shafahi}, Ali and {Najibi}, Mahyar and {Ghiasi}, Amin and {Xu}, Zheng and
         {Dickerson}, John and {Studer}, Christoph and {Davis}, Larry S. and
         {Taylor}, Gavin and {Goldstein}, Tom},
        title = "{Adversarial Training for Free!}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Machine Learning, Computer Science - Cryptography and Security, Computer Science - Computer Vision and Pattern Recognition, Statistics - Machine Learning},
         year = "2019",
        month = "Apr",
          eid = {arXiv:1904.12843},
        pages = {arXiv:1904.12843},
archivePrefix = {arXiv},
       eprint = {1904.12843},
 primaryClass = {cs.LG},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2019arXiv190412843S},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{ManipulatingInterpretability,
       author = {{Poursabzi-Sangdeh}, Forough and {Goldstein}, Daniel G. and
         {Hofman}, Jake M. and {Wortman Vaughan}, Jennifer and {Wallach}, Hanna},
        title = "{Manipulating and Measuring Model Interpretability}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Artificial Intelligence, Computer Science - Computers and Society},
         year = "2018",
        month = "Feb",
          eid = {arXiv:1802.07810},
        pages = {arXiv:1802.07810},
archivePrefix = {arXiv},
       eprint = {1802.07810},
 primaryClass = {cs.AI},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2018arXiv180207810P},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{EvaluationHumanInterpretability,
       author = {{Narayanan}, Menaka and {Chen}, Emily and {He}, Jeffrey and {Kim}, Been and
         {Gershman}, Sam and {Doshi-Velez}, Finale},
        title = "{How do Humans Understand Explanations from Machine Learning Systems? An Evaluation of the Human-Interpretability of Explanation}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Artificial Intelligence},
         year = "2018",
        month = "Feb",
          eid = {arXiv:1802.00682},
        pages = {arXiv:1802.00682},
archivePrefix = {arXiv},
       eprint = {1802.00682},
 primaryClass = {cs.AI},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2018arXiv180200682N},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{LyingGradients,
       author = {{Athalye}, Anish and {Carlini}, Nicholas and {Wagner}, David},
        title = "{Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Cryptography and Security},
         year = "2018",
        month = "Feb",
          eid = {arXiv:1802.00420},
        pages = {arXiv:1802.00420},
archivePrefix = {arXiv},
       eprint = {1802.00420},
 primaryClass = {cs.LG},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2018arXiv180200420A},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{SpatiallyTransformed,
       author = {{Xiao}, Chaowei and {Zhu}, Jun-Yan and {Li}, Bo and {He}, Warren and
         {Liu}, Mingyan and {Song}, Dawn},
        title = "{Spatially Transformed Adversarial Examples}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Cryptography and Security, Computer Science - Computer Vision and Pattern Recognition, Statistics - Machine Learning},
         year = "2018",
        month = "Jan",
          eid = {arXiv:1801.02612},
        pages = {arXiv:1801.02612},
archivePrefix = {arXiv},
       eprint = {1801.02612},
 primaryClass = {cs.CR},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2018arXiv180102612X},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{AdvGAN,
       author = {{Xiao}, Chaowei and {Li}, Bo and {Zhu}, Jun-Yan and {He}, Warren and
         {Liu}, Mingyan and {Song}, Dawn},
        title = "{Generating Adversarial Examples with Adversarial Networks}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Cryptography and Security, Computer Science - Computer Vision and Pattern Recognition, Statistics - Machine Learning},
         year = "2018",
        month = "Jan",
          eid = {arXiv:1801.02610},
        pages = {arXiv:1801.02610},
archivePrefix = {arXiv},
       eprint = {1801.02610},
 primaryClass = {cs.CR},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2018arXiv180102610X},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{VisualizingLossLandscape,
       author = {{Li}, Hao and {Xu}, Zheng and {Taylor}, Gavin and {Studer}, Christoph and
         {Goldstein}, Tom},
        title = "{Visualizing the Loss Landscape of Neural Nets}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Statistics - Machine Learning},
         year = "2017",
        month = "Dec",
          eid = {arXiv:1712.09913},
        pages = {arXiv:1712.09913},
archivePrefix = {arXiv},
       eprint = {1712.09913},
 primaryClass = {cs.LG},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2017arXiv171209913L},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{HighLevelDenoiser,
       author = {{Liao}, Fangzhou and {Liang}, Ming and {Dong}, Yinpeng and
         {Pang}, Tianyu and {Hu}, Xiaolin and {Zhu}, Jun},
        title = "{Defense against Adversarial Attacks Using High-Level Representation Guided Denoiser}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Computer Vision and Pattern Recognition},
         year = "2017",
        month = "Dec",
          eid = {arXiv:1712.02976},
        pages = {arXiv:1712.02976},
archivePrefix = {arXiv},
       eprint = {1712.02976},
 primaryClass = {cs.CV},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2017arXiv171202976L},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{UnderstandingImagenet,
       author = {{Stock}, Pierre and {Cisse}, Moustapha},
        title = "{ConvNets and ImageNet Beyond Accuracy: Understanding Mistakes and Uncovering Biases}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Computers and Society, Statistics - Machine Learning},
         year = "2017",
        month = "Nov",
          eid = {arXiv:1711.11443},
        pages = {arXiv:1711.11443},
archivePrefix = {arXiv},
       eprint = {1711.11443},
 primaryClass = {cs.LG},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2017arXiv171111443S},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{PromisePeril,
       author = {{Herman}, Bernease},
        title = "{The Promise and Peril of Human Evaluation for Model Interpretability}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
         year = "2017",
        month = "Nov",
          eid = {arXiv:1711.07414},
        pages = {arXiv:1711.07414},
archivePrefix = {arXiv},
       eprint = {1711.07414},
 primaryClass = {cs.AI},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2017arXiv171107414H},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{ProvableDefensesConvexPolytope,
       author = {{Wong}, Eric and {Zico Kolter}, J.},
        title = "{Provable defenses against adversarial examples via the convex outer adversarial polytope}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Mathematics - Optimization and Control},
         year = "2017",
        month = "Nov",
          eid = {arXiv:1711.00851},
        pages = {arXiv:1711.00851},
archivePrefix = {arXiv},
       eprint = {1711.00851},
 primaryClass = {cs.LG},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2017arXiv171100851W},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{AttackingMadryL1,
       author = {{Sharma}, Yash and {Chen}, Pin-Yu},
        title = "{Attacking the Madry Defense Model with $L_1$-based Adversarial Examples}",
      journal = {arXiv e-prints},
     keywords = {Statistics - Machine Learning, Computer Science - Cryptography and Security, Computer Science - Machine Learning},
         year = "2017",
        month = "Oct",
          eid = {arXiv:1710.10733},
        pages = {arXiv:1710.10733},
archivePrefix = {arXiv},
       eprint = {1710.10733},
 primaryClass = {stat.ML},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2017arXiv171010733S},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{PrincipledAdvTraining,
       author = {{Sinha}, Aman and {Namkoong}, Hongseok and {Duchi}, John},
        title = "{Certifying Some Distributional Robustness with Principled Adversarial Training}",
      journal = {arXiv e-prints},
     keywords = {Statistics - Machine Learning, Computer Science - Machine Learning},
         year = "2017",
        month = "Oct",
          eid = {arXiv:1710.10571},
        pages = {arXiv:1710.10571},
archivePrefix = {arXiv},
       eprint = {1710.10571},
 primaryClass = {stat.ML},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2017arXiv171010571S},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{MomentumIterativeAttack,
       author = {{Dong}, Yinpeng and {Liao}, Fangzhou and {Pang}, Tianyu and {Su}, Hang and
         {Zhu}, Jun and {Hu}, Xiaolin and {Li}, Jianguo},
        title = "{Boosting Adversarial Attacks with Momentum}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
         year = "2017",
        month = "Oct",
          eid = {arXiv:1710.06081},
        pages = {arXiv:1710.06081},
archivePrefix = {arXiv},
       eprint = {1710.06081},
 primaryClass = {cs.LG},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2017arXiv171006081D},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{ParsevalNetworks,
       author = {{Cisse}, Moustapha and {Bojanowski}, Piotr and {Grave}, Edouard and
         {Dauphin}, Yann and {Usunier}, Nicolas},
        title = "{Parseval Networks: Improving Robustness to Adversarial Examples}",
      journal = {arXiv e-prints},
     keywords = {Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Cryptography and Security, Computer Science - Machine Learning},
         year = "2017",
        month = "Apr",
          eid = {arXiv:1704.08847},
        pages = {arXiv:1704.08847},
archivePrefix = {arXiv},
       eprint = {1704.08847},
 primaryClass = {stat.ML},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2017arXiv170408847C},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{ProgramsAsExplanations,
       author = {{Singh}, Sameer and {Tulio Ribeiro}, Marco and {Guestrin}, Carlos},
        title = "{Programs as Black-Box Explanations}",
      journal = {arXiv e-prints},
     keywords = {Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
         year = "2016",
        month = "Nov",
          eid = {arXiv:1611.07579},
        pages = {arXiv:1611.07579},
archivePrefix = {arXiv},
       eprint = {1611.07579},
 primaryClass = {stat.ML},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2016arXiv161107579S},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{TowardsEvaluatingRobustness,
       author = {{Carlini}, Nicholas and {Wagner}, David},
        title = "{Towards Evaluating the Robustness of Neural Networks}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Cryptography and Security, Computer Science - Computer Vision and Pattern Recognition},
         year = "2016",
        month = "Aug",
          eid = {arXiv:1608.04644},
        pages = {arXiv:1608.04644},
archivePrefix = {arXiv},
       eprint = {1608.04644},
 primaryClass = {cs.CR},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2016arXiv160804644C},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{WideResNets,
       author = {{Zagoruyko}, Sergey and {Komodakis}, Nikos},
        title = "{Wide Residual Networks}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing},
         year = "2016",
        month = "May",
          eid = {arXiv:1605.07146},
        pages = {arXiv:1605.07146},
archivePrefix = {arXiv},
       eprint = {1605.07146},
 primaryClass = {cs.CV},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2016arXiv160507146Z},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{WhyShouldITrustYou,
       author = {{Tulio Ribeiro}, Marco and {Singh}, Sameer and {Guestrin}, Carlos},
        title = "{``Why Should I Trust You?'': Explaining the Predictions of Any Classifier}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Statistics - Machine Learning},
         year = "2016",
        month = "Feb",
          eid = {arXiv:1602.04938},
        pages = {arXiv:1602.04938},
archivePrefix = {arXiv},
       eprint = {1602.04938},
 primaryClass = {cs.LG},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2016arXiv160204938T},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{MagNet,
       author = {{Meng}, Dongyu and {Chen}, Hao},
        title = "{MagNet: a Two-Pronged Defense against Adversarial Examples}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Cryptography and Security, Computer Science - Machine Learning},
         year = "2017",
        month = "May",
          eid = {arXiv:1705.09064},
        pages = {arXiv:1705.09064},
archivePrefix = {arXiv},
       eprint = {1705.09064},
 primaryClass = {cs.CR},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2017arXiv170509064M},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{FeatureSqueezing,
       author = {{Xu}, Weilin and {Evans}, David and {Qi}, Yanjun},
        title = "{Feature Squeezing: Detecting Adversarial Examples in Deep Neural Networks}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Cryptography and Security, Computer Science - Machine Learning},
         year = "2017",
        month = "Apr",
          eid = {arXiv:1704.01155},
        pages = {arXiv:1704.01155},
archivePrefix = {arXiv},
       eprint = {1704.01155},
 primaryClass = {cs.CV},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2017arXiv170401155X},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{PracticalBlackBox,
       author = {{Papernot}, Nicolas and {McDaniel}, Patrick and {Goodfellow}, Ian and
         {Jha}, Somesh and {Berkay Celik}, Z. and {Swami}, Ananthram},
        title = "{Practical Black-Box Attacks against Machine Learning}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Cryptography and Security, Computer Science - Machine Learning},
         year = "2016",
        month = "Feb",
          eid = {arXiv:1602.02697},
        pages = {arXiv:1602.02697},
archivePrefix = {arXiv},
       eprint = {1602.02697},
 primaryClass = {cs.CR},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2016arXiv160202697P},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{ExplainingAdvExamples,
       author = {{Goodfellow}, Ian J. and {Shlens}, Jonathon and {Szegedy}, Christian},
        title = "{Explaining and Harnessing Adversarial Examples}",
      journal = {arXiv e-prints},
     keywords = {Statistics - Machine Learning, Computer Science - Machine Learning},
         year = "2014",
        month = "Dec",
          eid = {arXiv:1412.6572},
        pages = {arXiv:1412.6572},
archivePrefix = {arXiv},
       eprint = {1412.6572},
 primaryClass = {stat.ML},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2014arXiv1412.6572G},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{StochasticActPruning,
       author = {{Dhillon}, Guneet S. and {Azizzadenesheli}, Kamyar and
         {Lipton}, Zachary C. and {Bernstein}, Jeremy and {Kossaifi}, Jean and
         {Khanna}, Aran and {Anandkumar}, Anima},
        title = "{Stochastic Activation Pruning for Robust Adversarial Defense}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
         year = "2018",
        month = "Mar",
          eid = {arXiv:1803.01442},
        pages = {arXiv:1803.01442},
archivePrefix = {arXiv},
       eprint = {1803.01442},
 primaryClass = {cs.LG},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2018arXiv180301442D},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{SynthesizingRobust,
       author = {{Athalye}, Anish and {Engstrom}, Logan and {Ilyas}, Andrew and
         {Kwok}, Kevin},
        title = "{Synthesizing Robust Adversarial Examples}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Computer Vision and Pattern Recognition},
         year = "2017",
        month = "Jul",
          eid = {arXiv:1707.07397},
        pages = {arXiv:1707.07397},
archivePrefix = {arXiv},
       eprint = {1707.07397},
 primaryClass = {cs.CV},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2017arXiv170707397A},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@article{AlphaGo,
  author = {Silver, David and Huang, Aja and Maddison, Chris J. and Guez, Arthur and Sifre, Laurent and van den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and Dieleman, Sander and Grewe, Dominik and Nham, John and Kalchbrenner, Nal and Sutskever, Ilya and Lillicrap, Timothy and Leach, Madeleine and Kavukcuoglu, Koray and Graepel, Thore and Hassabis, Demis},
  biburl = {https://www.bibsonomy.org/bibtex/29e987f58d895c490144693139cbc90c7/flint63},
  doi = {10.1038/nature16961},
  file = {Nature online:2016/SilverHuangEtAl16nature.pdf:PDF},
  groups = {public},
  interhash = {48430c7891aaf9fe2582faa8f5d076c1},
  intrahash = {9e987f58d895c490144693139cbc90c7},
  issn = {0028-0836},
  journal = {Nature},
  keywords = {01614 paper ai google learn algorithm},
  month = {#jan#},
  number = 7587,
  pages = {484--489},
  timestamp = {2018-04-16T12:03:12.000+0200},
  title = {Mastering the Game of {Go} with Deep Neural Networks and Tree Search},
  username = {flint63},
  volume = 529,
  year = 2016
}

@misc{Alchemy,
    author = {Rahimi, Ali},
    year = {2017},
    title = {NIPS 2017 Test of Time Award Speech}
}

@article{InterpretationFragile, title={Interpretation of Neural Networks Is Fragile}, volume={33}, url={https://wvvw.aaai.org/ojs/index.php/AAAI/article/view/4252}, DOI={10.1609/aaai.v33i01.33013681}, number={01}, journal={Proceedings of the AAAI Conference on Artificial Intelligence}, author={Ghorbani, Amirata and Abid, Abubakar and Zou, James}, year={2019}, month={Jul.}, pages={3681-3688} }

@ARTICLE{RegularizingInputGradients,
       author = {{Slavin Ross}, Andrew and {Doshi-Velez}, Finale},
        title = "{Improving the Adversarial Robustness and Interpretability of Deep Neural Networks by Regularizing their Input Gradients}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Machine Learning, Computer Science - Cryptography and Security, Computer Science - Computer Vision and Pattern Recognition},
         year = "2017",
        month = "Nov",
          eid = {arXiv:1711.09404},
        pages = {arXiv:1711.09404},
archivePrefix = {arXiv},
       eprint = {1711.09404},
 primaryClass = {cs.LG},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2017arXiv171109404S},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}


@ARTICLE{ExplainingExplanations,
       author = {{Gilpin}, Leilani H. and {Bau}, David and {Yuan}, Ben Z. and
         {Bajwa}, Ayesha and {Specter}, Michael and {Kagal}, Lalana},
        title = "{Explaining Explanations: An Overview of Interpretability of Machine Learning}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
         year = "2018",
        month = "May",
          eid = {arXiv:1806.00069},
        pages = {arXiv:1806.00069},
archivePrefix = {arXiv},
       eprint = {1806.00069},
 primaryClass = {cs.AI},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2018arXiv180600069G},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}


@ARTICLE{DeepInsideConvNets,
       author = {{Simonyan}, Karen and {Vedaldi}, Andrea and {Zisserman}, Andrew},
        title = "{Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Computer Vision and Pattern Recognition},
         year = "2013",
        month = "Dec",
          eid = {arXiv:1312.6034},
        pages = {arXiv:1312.6034},
archivePrefix = {arXiv},
       eprint = {1312.6034},
 primaryClass = {cs.CV},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2013arXiv1312.6034S},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}


@incollection{Obligatory,
title = {ImageNet Classification with Deep Convolutional Neural Networks},
author = {Alex Krizhevsky and Sutskever, Ilya and Hinton, Geoffrey E},
booktitle = {Advances in Neural Information Processing Systems 25},
editor = {F. Pereira and C. J. C. Burges and L. Bottou and K. Q. Weinberger},
pages = {1097--1105},
year = {2012},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf}
}

@ARTICLE{HowHumansUnderstand,
       author = {{Narayanan}, Menaka and {Chen}, Emily and {He}, Jeffrey and {Kim}, Been and
         {Gershman}, Sam and {Doshi-Velez}, Finale},
        title = "{How do Humans Understand Explanations from Machine Learning Systems? An Evaluation of the Human-Interpretability of Explanation}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Artificial Intelligence},
         year = "2018",
        month = "Feb",
          eid = {arXiv:1802.00682},
        pages = {arXiv:1802.00682},
archivePrefix = {arXiv},
       eprint = {1802.00682},
 primaryClass = {cs.AI},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2018arXiv180200682N},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}


@ARTICLE{TowardsRigorousInterpretability,
       author = {{Doshi-Velez}, Finale and {Kim}, Been},
        title = "{Towards A Rigorous Science of Interpretable Machine Learning}",
      journal = {arXiv e-prints},
     keywords = {Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
         year = "2017",
        month = "Feb",
          eid = {arXiv:1702.08608},
        pages = {arXiv:1702.08608},
archivePrefix = {arXiv},
       eprint = {1702.08608},
 primaryClass = {stat.ML},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2017arXiv170208608D},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{Inceptionism,
    author = {Mordvintsev, Alexander, Olah, Christopher, and Tyka, Mike},
    year = "2015",
    month = "Jun",
    title = {Inceptionism: Going Deeper into Neural Networks},
    journal = {Google AI Blog},
}

@inproceedings{netdissect2017,
  title={Network Dissection: Quantifying Interpretability of Deep Visual Representations},
  author={Bau, David and Zhou, Bolei and Khosla, Aditya and Oliva, Aude and Torralba, Antonio},
  booktitle={Computer Vision and Pattern Recognition},
  year={2017}
}
@ARTICLE{FoolTimeLimitedHumans,
       author = {{Elsayed}, Gamaleldin F. and {Shankar}, Shreya and {Cheung}, Brian and
         {Papernot}, Nicolas and {Kurakin}, Alex and {Goodfellow}, Ian and
         {Sohl-Dickstein}, Jascha},
        title = "{Adversarial Examples that Fool both Computer Vision and Time-Limited Humans}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Quantitative Biology - Neurons and Cognition, Statistics - Machine Learning},
         year = "2018",
        month = "Feb",
          eid = {arXiv:1802.08195},
        pages = {arXiv:1802.08195},
archivePrefix = {arXiv},
       eprint = {1802.08195},
 primaryClass = {cs.LG},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2018arXiv180208195E},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}


@ARTICLE{CloserLookAtMemorization,
       author = {{Arpit}, Devansh and {Jastrz{\k{e}}bski}, Stanis{\l}aw and
         {Ballas}, Nicolas and {Krueger}, David and {Bengio}, Emmanuel and
         {Kanwal}, Maxinder S. and {Maharaj}, Tegan and {Fischer}, Asja and
         {Courville}, Aaron and {Bengio}, Yoshua and {Lacoste-Julien}, Simon},
        title = "{A Closer Look at Memorization in Deep Networks}",
      journal = {arXiv e-prints},
     keywords = {Statistics - Machine Learning, Computer Science - Machine Learning},
         year = "2017",
        month = "Jun",
          eid = {arXiv:1706.05394},
        pages = {arXiv:1706.05394},
archivePrefix = {arXiv},
       eprint = {1706.05394},
 primaryClass = {stat.ML},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2017arXiv170605394A},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}


@ARTICLE{LTH,
       author = {{Frankle}, Jonathan and {Carbin}, Michael},
        title = "{The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Neural and Evolutionary Computing},
         year = "2018",
        month = "Mar",
          eid = {arXiv:1803.03635},
        pages = {arXiv:1803.03635},
archivePrefix = {arXiv},
       eprint = {1803.03635},
 primaryClass = {cs.LG},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2018arXiv180303635F},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}


@ARTICLE{StabilizingLTH,
       author = {{Frankle}, Jonathan and {Karolina Dziugaite}, Gintare and
         {Roy}, Daniel M. and {Carbin}, Michael},
        title = "{Stabilizing the Lottery Ticket Hypothesis}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Statistics - Machine Learning},
         year = "2019",
        month = "Mar",
          eid = {arXiv:1903.01611},
        pages = {arXiv:1903.01611},
archivePrefix = {arXiv},
       eprint = {1903.01611},
 primaryClass = {cs.LG},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2019arXiv190301611F},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}
@article{RobustnessOrCompression,
  author =       {Ye, Shaokai and Xu, Kaidi and Liu, Sijia and Cheng, Hao and
                  Lambrechts, Jan-Henrik and Zhang, Huan and Zhou, Aojun and Ma,
                  Kaisheng and Wang, Yanzhi and Lin, Xue},
  title =        {Adversarial Robustness Vs Model Compression, Or Both?},
  journal =      {CoRR},
  year =         2019,
  url =          {http://arxiv.org/abs/1903.12561v4},
  abstract =     {It is well known that deep neural networks (DNNs) are
                  vulnerable to adversarial attacks, which are implemented by
                  adding crafted perturbations onto benign examples. Min-max
                  robust optimization based adversarial training can provide a
                  notion of security against adversarial attacks. However,
                  adversarial robustness requires a significantly larger
                  capacity of the network than that for the natural training
                  with only benign examples. This paper proposes a framework of
                  concurrent adversarial training and weight pruning that
                  enables model compression while still preserving the
                  adversarial robustness and essentially tackles the dilemma of
                  adversarial training. Furthermore, this work studies two
                  hypotheses about weight pruning in the conventional setting
                  and finds that weight pruning is essential for reducing the
                  network model size in the adversarial setting, training a
                  small model from scratch even with inherited initialization
                  from the large model cannot achieve both adversarial
                  robustness and high standard accuracy. Code is available at
                  https://github.com/yeshaokai/Robustness-Aware-Pruning-ADMM.},
  archivePrefix ={arXiv},
  eprint =       {1903.12561},
  primaryClass = {cs.CV},
}
@article{DelvingTransferable,
  author =       {Liu, Yanpei and Chen, Xinyun and Liu, Chang and Song, Dawn},
  title =        {Delving Into Transferable Adversarial Examples and Black-Box
                  Attacks},
  journal =      {CoRR},
  year =         2016,
  url =          {http://arxiv.org/abs/1611.02770v3},
  abstract =     {An intriguing property of deep neural networks is the
                  existence of adversarial examples, which can transfer among
                  different architectures. These transferable adversarial
                  examples may severely hinder deep neural network-based
                  applications. Previous works mostly study the transferability
                  using small scale datasets. In this work, we are the first to
                  conduct an extensive study of the transferability over large
                  models and a large scale dataset, and we are also the first to
                  study the transferability of targeted adversarial examples
                  with their target labels. We study both non-targeted and
                  targeted adversarial examples, and show that while
                  transferable non-targeted adversarial examples are easy to
                  find, targeted adversarial examples generated using existing
                  approaches almost never transfer with their target labels.
                  Therefore, we propose novel ensemble-based approaches to
                  generating transferable adversarial examples. Using such
                  approaches, we observe a large proportion of targeted
                  adversarial examples that are able to transfer with their
                  target labels for the first time. We also present some
                  geometric studies to help understanding the transferable
                  adversarial examples. Finally, we show that the adversarial
                  examples generated using ensemble-based approaches can
                  successfully attack Clarifai.com, which is a black-box image
                  classification system.},
  archivePrefix ={arXiv},
  eprint =       {1611.02770},
  primaryClass = {cs.LG},
}

@article{SpaceOfTransferableAdv,
  journal = {CoRR},
  title = {The Space of Transferable Adversarial Examples},
  author = {Tram{\`e}r, Florian and Papernot, Nicolas and Goodfellow, Ian and Boneh, Dan and McDaniel, Patrick},
  archivePrefix = {arXiv},
  year = {2017},
  eprint = {1704.03453},
  primaryClass = {stat.ML},
  abstract = {Adversarial examples are maliciously perturbed inputs designed to mislead
machine learning (ML) models at test-time. They often transfer: the same
adversarial example fools more than one model.
  In this work, we propose novel methods for estimating the previously unknown
dimensionality of the space of adversarial inputs. We find that adversarial
examples span a contiguous subspace of large (~25) dimensionality. Adversarial
subspaces with higher dimensionality are more likely to intersect. We find that
for two different models, a significant fraction of their subspaces is shared,
thus enabling transferability.
  In the first quantitative analysis of the similarity of different models'
decision boundaries, we show that these boundaries are actually close in
arbitrary directions, whether adversarial or benign. We conclude by formally
studying the limits of transferability. We derive (1) sufficient conditions on
the data distribution that imply transferability for simple model classes and
(2) examples of scenarios in which transfer does not occur. These findings
indicate that it may be possible to design defenses against transfer-based
attacks, even for models that are vulnerable to direct attacks.},
  url = {http://arxiv.org/abs/1704.03453v2},
}
@article{StrongerGeneralizationBounds,
  author =       {Arora, Sanjeev and Ge, Rong and Neyshabur, Behnam and Zhang,
                  Yi},
  title =        {Stronger Generalization Bounds for Deep Nets Via a Compression
                  Approach},
  journal =      {CoRR},
  year =         2018,
  url =          {http://arxiv.org/abs/1802.05296v4},
  abstract =     {Deep nets generalize well despite having more parameters than
                  the number of training samples. Recent works try to give an
                  explanation using PAC-Bayes and Margin-based analyses, but do
                  not as yet result in sample complexity bounds better than
                  naive parameter counting. The current paper shows
                  generalization bounds that're orders of magnitude better in
                  practice. These rely upon new succinct reparametrizations of
                  the trained net --- a compression that is explicit and
                  efficient. These yield generalization bounds via a simple
                  compression-based framework introduced here. Our results also
                  provide some theoretical justification for widespread
                  empirical success in compressing deep nets. Analysis of
                  correctness of our compression relies upon some newly
                  identified \textquotedblleft noise stability\textquotedblright
                  properties of trained deep nets, which are also experimentally
                  verified. The study of these properties and resulting
                  generalization bounds are also extended to convolutional nets,
                  which had eluded earlier attempts on proving generalization.},
  archivePrefix ={arXiv},
  eprint =       {1802.05296},
  primaryClass = {cs.LG},
}
@article{QuantifyingDiscarding,
  author =       {Ma, Haotian and Zhang, Yinqing and Zhou, Fan and Zhang,
                  Quanshi},
  title =        {Quantifying Layerwise Information Discarding of Neural
                  Networks},
  journal =      {CoRR},
  year =         2019,
  url =          {http://arxiv.org/abs/1906.04109v1},
  abstract =     {This paper presents a method to explain how input information
                  is discarded through intermediate layers of a neural network
                  during the forward propagation, in order to quantify and
                  diagnose knowledge representations of pre-trained deep neural
                  networks. We define two types of entropy-based metrics, i.e.,
                  the strict information discarding and the reconstruction
                  uncertainty, which measure input information of a specific
                  layer from two perspectives. We develop a method to enable
                  efficient computation of such entropy-based metrics. Our
                  method can be broadly applied to various neural networks and
                  enable comprehensive comparisons between different layers of
                  different networks. Preliminary experiments have shown the
                  effectiveness of our metrics in analyzing benchmark networks
                  and explaining existing deep-learning techniques.},
  archivePrefix ={arXiv},
  eprint =       {1906.04109},
  primaryClass = {cs.LG},
}
@article{GeneralizationErrorDynamics,
  author =       {Advani, Madhu S. and Saxe, Andrew M.},
  title =        {High-Dimensional Dynamics of Generalization Error in Neural
                  Networks},
  journal =      {CoRR},
  year =         2017,
  url =          {http://arxiv.org/abs/1710.03667v1},
  abstract =     {We perform an average case analysis of the generalization
                  dynamics of large neural networks trained using gradient
                  descent. We study the practically-relevant "high-dimensional"
                  regime where the number of free parameters in the network is
                  on the order of or even larger than the number of examples in
                  the dataset. Using random matrix theory and exact solutions in
                  linear models, we derive the generalization error and training
                  error dynamics of learning and analyze how they depend on the
                  dimensionality of data and signal to noise ratio of the
                  learning problem. We find that the dynamics of gradient
                  descent learning naturally protect against overtraining and
                  overfitting in large networks. Overtraining is worst at
                  intermediate network sizes, when the effective number of free
                  parameters equals the number of samples, and thus can be
                  reduced by making a network smaller or larger. Additionally,
                  in the high-dimensional regime, low generalization error
                  requires starting with small initial weights. We then turn to
                  non-linear neural networks, and show that making networks very
                  large does not harm their generalization performance. On the
                  contrary, it can in fact reduce overtraining, even without
                  early stopping or regularization of any sort. We identify two
                  novel phenomena underlying this behavior in overcomplete
                  models: first, there is a frozen subspace of the weights in
                  which no learning occurs under gradient descent; and second,
                  the statistical properties of the high-dimensional regime
                  yield better-conditioned input correlations which protect
                  against overtraining. We demonstrate that naive application of
                  worst-case theories such as Rademacher complexity are
                  inaccurate in predicting the generalization performance of
                  deep neural networks, and derive an alternative bound which
                  incorporates the frozen subspace and conditioning effects and
                  qualitatively matches the behavior observed in simulation.},
  archivePrefix ={arXiv},
  eprint =       {1710.03667},
  primaryClass = {stat.ML},
}
@article{StructADMM,
  author =       {Zhang, Tianyun and Ye, Shaokai and Zhang, Kaiqi and Ma,
                  Xiaolong and Liu, Ning and Zhang, Linfeng and Tang, Jian and
                  Ma, Kaisheng and Lin, Xue and Fardad, Makan and Wang, Yanzhi},
  title =        {StructADMM: a Systematic, High-Efficiency Framework of
                  Structured Weight Pruning for Dnns},
  journal =      {CoRR},
  year =         2018,
  url =          {http://arxiv.org/abs/1807.11091v3},
  abstract =     {Weight pruning methods of DNNs have been demonstrated to
                  achieve a good model pruning rate without loss of accuracy,
                  thereby alleviating the significant computation/storage
                  requirements of large-scale DNNs. Structured weight pruning
                  methods have been proposed to overcome the limitation of
                  irregular network structure and demonstrated actual GPU
                  acceleration. However, in prior work the pruning rate (degree
                  of sparsity) and GPU acceleration are limited (to less than 50
                  \%) when accuracy needs to be maintained. In this work,we
                  overcome these limitations by proposing a unified, systematic
                  framework of structured weight pruning for DNNs. It is a
                  framework that can be used to induce different types of
                  structured sparsity, such as filter-wise, channel-wise, and
                  shape-wise sparsity, as well non-structured sparsity. The
                  proposed framework incorporates stochastic gradient descent
                  with ADMM, and can be understood as a dynamic regularization
                  method in which the regularization target is analytically
                  updated in each iteration. Without loss of accuracy on the
                  AlexNet model, we achieve 2.58X and 3.65X average measured
                  speedup on two GPUs, clearly outperforming the prior work. The
                  average speedups reach 3.15X and 8.52X when allowing a
                  moderate ac-curacy loss of 2 \%. In this case the model
                  compression for convolutional layers is 15.0X, corresponding
                  to 11.93X measured CPU speedup. Our experiments on ResNet
                  model and on other data sets like UCF101 and CIFAR-10
                  demonstrate the consistently higher performance of our
                  framework.},
  archivePrefix ={arXiv},
  eprint =       {1807.11091},
  primaryClass = {cs.NE},
}
@article{AdvTowardsInterpretability,
  author =       {Dong, Yinpeng and Bao, Fan and Su, Hang and Zhu, Jun},
  title =        {Towards Interpretable Deep Neural Networks By Leveraging
                  Adversarial Examples},
  journal =      {CoRR},
  year =         2019,
  url =          {http://arxiv.org/abs/1901.09035v1},
  abstract =     {Sometimes it is not enough for a DNN to produce an outcome.
                  For example, in applications such as healthcare, users need to
                  understand the rationale of the decisions. Therefore, it is
                  imperative to develop algorithms to learn models with good
                  interpretability (Doshi-Velez 2017). An important factor that
                  leads to the lack of interpretability of DNNs is the ambiguity
                  of neurons, where a neuron may fire for various unrelated
                  concepts. This work aims to increase the interpretability of
                  DNNs on the whole image space by reducing the ambiguity of
                  neurons. In this paper, we make the following contributions:
                  1) We propose a metric to evaluate the consistency level of
                  neurons in a network quantitatively. 2) We find that the
                  learned features of neurons are ambiguous by leveraging
                  adversarial examples. 3) We propose to improve the consistency
                  of neurons on adversarial example subset by an adversarial
                  training algorithm with a consistent loss.},
  archivePrefix ={arXiv},
  eprint =       {1901.09035},
  primaryClass = {cs.LG},
}
@article{BatchNormBad,
  author =       {Galloway, Angus and Golubeva, Anna and Tanay, Thomas and
                  Moussa, Medhat and Taylor, Graham W.},
  title =        {Batch Normalization Is a Cause of Adversarial Vulnerability},
  journal =      {CoRR},
  year =         2019,
  url =          {http://arxiv.org/abs/1905.02161v2},
  abstract =     {Batch normalization (batch norm) is often used in an attempt
                  to stabilize and accelerate training in deep neural networks.
                  In many cases it indeed decreases the number of parameter
                  updates required to achieve low training error. However, it
                  also reduces robustness to small adversarial input
                  perturbations and noise by double-digit percentages, as we
                  show on five standard datasets. Furthermore, substituting
                  weight decay for batch norm is sufficient to nullify the
                  relationship between adversarial vulnerability and the input
                  dimension. Our work is consistent with a mean-field analysis
                  that found that batch norm causes exploding gradients.},
  archivePrefix ={arXiv},
  eprint =       {1905.02161},
  primaryClass = {cs.LG},
}
@article{RandomizedSmoothing,
  author =       {Cohen, Jeremy M and Rosenfeld, Elan and Kolter, J. Zico},
  title =        {Certified Adversarial Robustness Via Randomized Smoothing},
  journal =      {CoRR},
  year =         2019,
  url =          {http://arxiv.org/abs/1902.02918v2},
  abstract =     {We show how to turn any classifier that classifies well under
                  Gaussian noise into a new classifier that is certifiably
                  robust to adversarial perturbations under the $\ell_2$ norm.
                  This "randomized smoothing" technique has been proposed
                  recently in the literature, but existing guarantees are loose.
                  We prove a tight robustness guarantee in $\ell_2$ norm for
                  smoothing with Gaussian noise. We use randomized smoothing to
                  obtain an ImageNet classifier with e.g. a certified top-1
                  accuracy of 49 \% under adversarial perturbations with
                  $\ell_2$ norm less than 0.5 (=127/255). No certified defense
                  has been shown feasible on ImageNet except for smoothing. On
                  smaller-scale datasets where competing approaches to certified
                  $\ell_2$ robustness are viable, smoothing delivers higher
                  certified accuracies. Our strong empirical results suggest
                  that randomized smoothing is a promising direction for future
                  research into adversarially robust classification. Code and
                  models are available at http://github.com/locuslab/smoothing.},
  archivePrefix ={arXiv},
  eprint =       {1902.02918},
  primaryClass = {cs.LG},
}
@article{NoBarriers,
  author =       {Draxler, Felix and Veschgini, Kambis and Salmhofer, Manfred
                  and Hamprecht, Fred A.},
  title =        {Essentially No Barriers in Neural Network Energy Landscape},
  journal =      {CoRR},
  year =         2018,
  url =          {http://arxiv.org/abs/1803.00885v5},
  abstract =     {Training neural networks involves finding minima of a
                  high-dimensional non-convex loss function. Knowledge of the
                  structure of this energy landscape is sparse. Relaxing from
                  linear interpolations, we construct continuous paths between
                  minima of recent neural network architectures on CIFAR10 and
                  CIFAR100. Surprisingly, the paths are essentially flat in both
                  the training and test landscapes. This implies that neural
                  networks have enough capacity for structural changes, or that
                  these changes are small between minima. Also, each minimum has
                  at least one vanishing Hessian eigenvalue in addition to those
                  resulting from trivial invariance.},
  archivePrefix ={arXiv},
  eprint =       {1803.00885},
  primaryClass = {stat.ML},
}
@article{GeneralizationStatMech,
  author =       {Martin, Charles H. and Mahoney, Michael W.},
  title =        {Rethinking Generalization Requires Revisiting Old Ideas:
                  Statistical Mechanics Approaches and Complex Learning
                  Behavior},
  journal =      {CoRR},
  year =         2017,
  url =          {http://arxiv.org/abs/1710.09553v2},
  abstract =     {We describe an approach to understand the peculiar and
                  counterintuitive generalization properties of deep neural
                  networks. The approach involves going beyond worst-case
                  theoretical capacity control frameworks that have been popular
                  in machine learning in recent years to revisit old ideas in
                  the statistical mechanics of neural networks. Within this
                  approach, we present a prototypical Very Simple Deep Learning
                  (VSDL) model, whose behavior is controlled by two control
                  parameters, one describing an effective amount of data, or
                  load, on the network (that decreases when noise is added to
                  the input), and one with an effective temperature
                  interpretation (that increases when algorithms are early
                  stopped). Using this model, we describe how a very simple
                  application of ideas from the statistical mechanics theory of
                  generalization provides a strong qualitative description of
                  recently-observed empirical results regarding the inability of
                  deep neural networks not to overfit training data,
                  discontinuous learning and sharp transitions in the
                  generalization properties of learning algorithms, etc.},
  archivePrefix ={arXiv},
  eprint =       {1710.09553},
  primaryClass = {cs.LG},
}
@article{StatMechRL,
  author =       {Rahme, Jad and Adams, Ryan P.},
  title =        {A Theoretical Connection Between Statistical Physics and
                  Reinforcement Learning},
  journal =      {CoRR},
  year =         2019,
  url =          {http://arxiv.org/abs/1906.10228v1},
  abstract =     {Sequential decision making in the presence of uncertainty and
                  stochastic dynamics gives rise to distributions over
                  state/action trajectories in reinforcement learning (RL) and
                  optimal control problems. This observation has led to a
                  variety of connections between RL and inference in
                  probabilistic graphical models (PGMs). Here we explore a
                  different dimension to this relationship, examining
                  reinforcement learning using the tools and abstractions of
                  statistical physics. The central object in the statistical
                  physics abstraction is the idea of a partition function
                  $\mathcal{Z}$, and here we construct a partition function from
                  the ensemble of possible trajectories that an agent might take
                  in a Markov decision process. Although value functions and
                  $Q$-functions can be derived from this partition function and
                  interpreted via average energies, the $\mathcal{Z}$-function
                  provides an object with its own Bellman equation that can form
                  the basis of alternative dynamic programming approaches.
                  Moreover, when the MDP dynamics are deterministic, the Bellman
                  equation for $\mathcal{Z}$ is linear, allowing direct
                  solutions that are unavailable for the nonlinear equations
                  associated with traditional value functions. The policies
                  learned via these $\mathcal{Z}$-based Bellman updates are
                  tightly linked to Boltzmann-like policy parameterizations. In
                  addition to sampling actions proportionally to the exponential
                  of the expected cumulative reward as Boltzmann policies would,
                  these policies take entropy into account favoring states from
                  which many outcomes are possible.},
  archivePrefix ={arXiv},
  eprint =       {1906.10228},
  primaryClass = {cs.LG},
}
@article{HypergradientDescent,
  author =       {Baydin, Atilim Gunes and Cornish, Robert and Rubio, David
                  Martinez and Schmidt, Mark and Wood, Frank},
  title =        {Online Learning Rate Adaptation With Hypergradient Descent},
  journal =      {CoRR},
  year =         2017,
  url =          {http://arxiv.org/abs/1703.04782v3},
  abstract =     {We introduce a general method for improving the convergence
                  rate of gradient-based optimizers that is easy to implement
                  and works well in practice. We demonstrate the effectiveness
                  of the method in a range of optimization problems by applying
                  it to stochastic gradient descent, stochastic gradient descent
                  with Nesterov momentum, and Adam, showing that it
                  significantly reduces the need for the manual tuning of the
                  initial learning rate for these commonly used algorithms. Our
                  method works by dynamically updating the learning rate during
                  optimization using the gradient with respect to the learning
                  rate of the update rule itself. Computing this "hypergradient"
                  needs little additional computation, requires only one extra
                  copy of the original gradient to be stored in memory, and
                  relies upon nothing more than what is provided by reverse-mode
                  automatic differentiation.},
  archivePrefix ={arXiv},
  eprint =       {1703.04782},
  primaryClass = {cs.LG},
}
@article{RethinkingGeneralization,
  author =       {Zhang, Chiyuan and Bengio, Samy and Hardt, Moritz and Recht,
                  Benjamin and Vinyals, Oriol},
  title =        {Understanding Deep Learning Requires Rethinking
                  Generalization},
  journal =      {CoRR},
  year =         2016,
  url =          {http://arxiv.org/abs/1611.03530v2},
  abstract =     {Despite their massive size, successful deep artificial neural
                  networks can exhibit a remarkably small difference between
                  training and test performance. Conventional wisdom attributes
                  small generalization error either to properties of the model
                  family, or to the regularization techniques used during
                  training. Through extensive systematic experiments, we show
                  how these traditional approaches fail to explain why large
                  neural networks generalize well in practice. Specifically, our
                  experiments establish that state-of-the-art convolutional
                  networks for image classification trained with stochastic
                  gradient methods easily fit a random labeling of the training
                  data. This phenomenon is qualitatively unaffected by explicit
                  regularization, and occurs even if we replace the true images
                  by completely unstructured random noise. We corroborate these
                  experimental findings with a theoretical construction showing
                  that simple depth two neural networks already have perfect
                  finite sample expressivity as soon as the number of parameters
                  exceeds the number of data points as it usually does in
                  practice. We interpret our experimental findings by comparison
                  with traditional models.},
  archivePrefix ={arXiv},
  eprint =       {1611.03530},
  primaryClass = {cs.LG},
}
@article{ImplicitSelfRegularization,
  author =       {Martin, Charles H. and Mahoney, Michael W.},
  title =        {Implicit Self-Regularization in Deep Neural Networks: Evidence
                  From Random Matrix Theory and Implications for Learning},
  journal =      {CoRR},
  year =         2018,
  url =          {http://arxiv.org/abs/1810.01075v1},
  abstract =     {Random Matrix Theory (RMT) is applied to analyze weight
                  matrices of Deep Neural Networks (DNNs), including both
                  production quality, pre-trained models such as AlexNet and
                  Inception, and smaller models trained from scratch, such as
                  LeNet5 and a miniature-AlexNet. Empirical and theoretical
                  results clearly indicate that the DNN training process itself
                  implicitly implements a form of Self-Regularization. The
                  empirical spectral density (ESD) of DNN layer matrices
                  displays signatures of traditionally-regularized statistical
                  models, even in the absence of exogenously specifying
                  traditional forms of explicit regularization. Building on
                  relatively recent results in RMT, most notably its extension
                  to Universality classes of Heavy-Tailed matrices, we develop a
                  theory to identify 5+1 Phases of Training, corresponding to
                  increasing amounts of Implicit Self-Regularization. These
                  phases can be observed during the training process as well as
                  in the final learned DNNs. For smaller and/or older DNNs, this
                  Implicit Self-Regularization is like traditional Tikhonov
                  regularization, in that there is a "size scale" separating
                  signal from noise. For state-of-the-art DNNs, however, we
                  identify a novel form of Heavy-Tailed Self-Regularization,
                  similar to the self-organization seen in the statistical
                  physics of disordered systems. This results from correlations
                  arising at all size scales, which arises implicitly due to the
                  training process itself. This implicit Self-Regularization can
                  depend strongly on the many knobs of the training process. By
                  exploiting the generalization gap phenomena, we demonstrate
                  that we can cause a small model to exhibit all 5+1 phases of
                  training simply by changing the batch size. This demonstrates
                  that---all else being equal---DNN optimization with larger
                  batch sizes leads to less-well implicitly-regularized models,
                  and it provides an explanation for the generalization gap
                  phenomena.},
  archivePrefix ={arXiv},
  eprint =       {1810.01075},
  primaryClass = {cs.LG},
}
@article{SpinGlassPedestrians,
  author =       {Castellani, Tommaso and Cavagna, Andrea},
  title =        {Spin-Glass Theory for Pedestrians},
  journal =      {CoRR},
  year =         2005,
  url =          {http://arxiv.org/abs/cond-mat/0505032v1},
  abstract =     {In these notes the main theoretical concepts and techniques in
                  the field of mean-field spin-glasses are reviewed in a compact
                  and pedagogical way, for the benefit of the graduate and
                  undergraduate student. One particular spin-glass model is
                  analyzed (the p-spin spherical model) by using three different
                  approaches. Thermodynamics, covering pure states, overlaps,
                  overlap distribution, replica symmetry breaking, and the
                  static transition. Dynamics, covering the generating
                  functional method, generalized Langevin equation, equations
                  for the correlation and the response, the Mode Coupling
                  approximation, and the dynamical transition. And finally
                  complexity, covering the mean-field (TAP) free energy,
                  metastable states, entropy crisis, threshold energy, and
                  saddles. Particular attention has been paid on the mutual
                  consistency of the results obtained from the different
                  methods.},
  archivePrefix ={arXiv},
  eprint =       {cond-mat/0505032},
  primaryClass = {cond-mat.dis-nn},
}
@article{SelfRegularizationRMT,
  author =       {Martin, Charles H. and Mahoney, Michael W.},
  title =        {Traditional and Heavy-Tailed Self Regularization in Neural
                  Network Models},
  journal =      {CoRR},
  year =         2019,
  url =          {http://arxiv.org/abs/1901.08276v1},
  abstract =     {Random Matrix Theory (RMT) is applied to analyze the weight
                  matrices of Deep Neural Networks (DNNs), including both
                  production quality, pre-trained models such as AlexNet and
                  Inception, and smaller models trained from scratch, such as
                  LeNet5 and a miniature-AlexNet. Empirical and theoretical
                  results clearly indicate that the empirical spectral density
                  (ESD) of DNN layer matrices displays signatures of
                  traditionally-regularized statistical models, even in the
                  absence of exogenously specifying traditional forms of
                  regularization, such as Dropout or Weight Norm constraints.
                  Building on recent results in RMT, most notably its extension
                  to Universality classes of Heavy-Tailed matrices, we develop a
                  theory to identify \emph{5+1 Phases of Training},
                  corresponding to increasing amounts of \emph{Implicit
                  Self-Regularization}. For smaller and/or older DNNs, this
                  Implicit Self-Regularization is like traditional Tikhonov
                  regularization, in that there is a `size scale' separating
                  signal from noise. For state-of-the-art DNNs, however, we
                  identify a novel form of \emph{Heavy-Tailed
                  Self-Regularization}, similar to the self-organization seen in
                  the statistical physics of disordered systems. This implicit
                  Self-Regularization can depend strongly on the many knobs of
                  the training process. By exploiting the generalization gap
                  phenomena, we demonstrate that we can cause a small model to
                  exhibit all 5+1 phases of training simply by changing the
                  batch size.},
  archivePrefix ={arXiv},
  eprint =       {1901.08276},
  primaryClass = {cs.LG},
}
@inproceedings{
anonymous2020boosting,
title={Boosting Ticket: Towards Practical Pruning for Adversarial Training with Lottery Ticket Hypothesis},
author={Anonymous},
booktitle={Submitted to International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=Sye2c3NYDB},
note={under review}
}
@article{PhysicsInformedDLI,
  author =       {Raissi, Maziar and Perdikaris, Paris and Karniadakis, George
                  Em},
  title =        {Physics Informed Deep Learning (Part I): Data-Driven Solutions
                  of Nonlinear Partial Differential Equations},
  journal =      {CoRR},
  year =         2017,
  url =          {http://arxiv.org/abs/1711.10561v1},
  abstract =     {We introduce physics informed neural networks -- neural
                  networks that are trained to solve supervised learning tasks
                  while respecting any given law of physics described by general
                  nonlinear partial differential equations. In this two part
                  treatise, we present our developments in the context of
                  solving two main classes of problems: data-driven solution and
                  data-driven discovery of partial differential equations.
                  Depending on the nature and arrangement of the available data,
                  we devise two distinct classes of algorithms, namely
                  continuous time and discrete time models. The resulting neural
                  networks form a new class of data-efficient universal function
                  approximators that naturally encode any underlying physical
                  laws as prior information. In this first part, we demonstrate
                  how these networks can be used to infer solutions to partial
                  differential equations, and obtain physics-informed surrogate
                  models that are fully differentiable with respect to all input
                  coordinates and free parameters.},
  archivePrefix ={arXiv},
  eprint =       {1711.10561},
  primaryClass = {cs.AI},
}
@article{PhysicsInformedDLII,
  author =       {Raissi, Maziar and Perdikaris, Paris and Karniadakis, George
                  Em},
  title =        {Physics Informed Deep Learning (Part II): Data-Driven
                  Discovery of Nonlinear Partial Differential Equations},
  journal =      {CoRR},
  year =         2017,
  url =          {http://arxiv.org/abs/1711.10566v1},
  abstract =     {We introduce physics informed neural networks -- neural
                  networks that are trained to solve supervised learning tasks
                  while respecting any given law of physics described by general
                  nonlinear partial differential equations. In this second part
                  of our two-part treatise, we focus on the problem of
                  data-driven discovery of partial differential equations.
                  Depending on whether the available data is scattered in
                  space-time or arranged in fixed temporal snapshots, we
                  introduce two main classes of algorithms, namely continuous
                  time and discrete time models. The effectiveness of our
                  approach is demonstrated using a wide range of benchmark
                  problems in mathematical physics, including conservation laws,
                  incompressible fluid flow, and the propagation of nonlinear
                  shallow-water waves.},
  archivePrefix ={arXiv},
  eprint =       {1711.10566},
  primaryClass = {cs.AI},
}
@article{LossSurfacesOfMultilayerNetworks,
  author =       {Choromanska, Anna and Henaff, Mikael and Mathieu, Michael and
                  Arous, G{\'e}rard Ben and LeCun, Yann},
  title =        {The Loss Surfaces of Multilayer Networks},
  journal =      {CoRR},
  year =         2014,
  url =          {http://arxiv.org/abs/1412.0233v3},
  abstract =     {We study the connection between the highly non-convex loss
                  function of a simple model of the fully-connected feed-forward
                  neural network and the Hamiltonian of the spherical spin-glass
                  model under the assumptions of: i) variable independence, ii)
                  redundancy in network parametrization, and iii) uniformity.
                  These assumptions enable us to explain the complexity of the
                  fully decoupled neural network through the prism of the
                  results from random matrix theory. We show that for large-size
                  decoupled networks the lowest critical values of the random
                  loss function form a layered structure and they are located in
                  a well-defined band lower-bounded by the global minimum. The
                  number of local minima outside that band diminishes
                  exponentially with the size of the network. We empirically
                  verify that the mathematical model exhibits similar behavior
                  as the computer simulations, despite the presence of high
                  dependencies in real networks. We conjecture that both
                  simulated annealing and SGD converge to the band of low
                  critical points, and that all critical points found there are
                  local minima of high quality measured by the test error. This
                  emphasizes a major difference between large- and small-size
                  networks where for the latter poor quality local minima have
                  non-zero probability of being recovered. Finally, we prove
                  that recovering the global minimum becomes harder as the
                  network size increases and that it is in practice irrelevant
                  as global minimum often leads to overfitting.},
  archivePrefix ={arXiv},
  eprint =       {1412.0233},
  primaryClass = {cs.LG},
}
@article{OpeningViaInformation,
  author =       {Shwartz-Ziv, Ravid and Tishby, Naftali},
  title =        {Opening the Black Box of Deep Neural Networks Via Information},
  journal =      {CoRR},
  year =         2017,
  url =          {http://arxiv.org/abs/1703.00810v3},
  abstract =     {Despite their great success, there is still no comprehensive
                  theoretical understanding of learning with Deep Neural
                  Networks (DNNs) or their inner organization. Previous work
                  proposed to analyze DNNs in the \textit{Information Plane};
                  i.e., the plane of the Mutual Information values that each
                  layer preserves on the input and output variables. They
                  suggested that the goal of the network is to optimize the
                  Information Bottleneck (IB) tradeoff between compression and
                  prediction, successively, for each layer. In this work we
                  follow up on this idea and demonstrate the effectiveness of
                  the Information-Plane visualization of DNNs. Our main results
                  are: (i) most of the training epochs in standard DL are spent
                  on {\emph compression} of the input to efficient
                  representation and not on fitting the training labels. (ii)
                  The representation compression phase begins when the training
                  errors becomes small and the Stochastic Gradient Decent (SGD)
                  epochs change from a fast drift to smaller training error into
                  a stochastic relaxation, or random diffusion, constrained by
                  the training error value. (iii) The converged layers lie on or
                  very close to the Information Bottleneck (IB) theoretical
                  bound, and the maps from the input to any hidden layer and
                  from this hidden layer to the output satisfy the IB
                  self-consistent equations. This generalization through noise
                  mechanism is unique to Deep Neural Networks and absent in one
                  layer networks. (iv) The training time is dramatically reduced
                  when adding more hidden layers. Thus the main advantage of the
                  hidden layers is computational. This can be explained by the
                  reduced relaxation time, as this it scales super-linearly
                  (exponentially for simple diffusion) with the information
                  compression from the previous layer.},
  archivePrefix ={arXiv},
  eprint =       {1703.00810},
  primaryClass = {cs.LG},
}

@article{EmitCarbon, title={Training a single AI model can emit as much carbon as five cars in their lifetimes}, journal={MIT Technology Review}, author={Hao, Karen}, year={2019}, month={Jun}}
@article{XNORNets,
  author =       {Rastegari, Mohammad and Ordonez, Vicente and Redmon, Joseph
                  and Farhadi, Ali},
  title =        {Xnor-Net: Imagenet Classification Using Binary Convolutional
                  Neural Networks},
  journal =      {CoRR},
  year =         2016,
  url =          {http://arxiv.org/abs/1603.05279v4},
  abstract =     {We propose two efficient approximations to standard
                  convolutional neural networks: Binary-Weight-Networks and
                  XNOR-Networks. In Binary-Weight-Networks, the filters are
                  approximated with binary values resulting in 32x memory
                  saving. In XNOR-Networks, both the filters and the input to
                  convolutional layers are binary. XNOR-Networks approximate
                  convolutions using primarily binary operations. This results
                  in 58x faster convolutional operations and 32x memory savings.
                  XNOR-Nets offer the possibility of running state-of-the-art
                  networks on CPUs (rather than GPUs) in real-time. Our binary
                  networks are simple, accurate, efficient, and work on
                  challenging visual tasks. We evaluate our approach on the
                  ImageNet classification task. The classification accuracy with
                  a Binary-Weight-Network version of AlexNet is only 2.9 \% less
                  than the full-precision AlexNet (in top-1 measure). We compare
                  our method with recent network binarization methods,
                  BinaryConnect and BinaryNets, and outperform these methods by
                  large margins on ImageNet, more than 16 \% in top-1 accuracy.},
  archivePrefix ={arXiv},
  eprint =       {1603.05279},
  primaryClass = {cs.CV},
}
@article{ABCNets,
  author =       {Lin, Xiaofan and Zhao, Cong and Pan, Wei},
  title =        {Towards Accurate Binary Convolutional Neural Network},
  journal =      {CoRR},
  year =         2017,
  url =          {http://arxiv.org/abs/1711.11294v1},
  abstract =     {We introduce a novel scheme to train binary convolutional
                  neural networks (CNNs) -- CNNs with weights and activations
                  constrained to {-1,+1} at run-time. It has been known that
                  using binary weights and activations drastically reduce memory
                  size and accesses, and can replace arithmetic operations with
                  more efficient bitwise operations, leading to much faster
                  test-time inference and lower power consumption. However,
                  previous works on binarizing CNNs usually result in severe
                  prediction accuracy degradation. In this paper, we address
                  this issue with two major innovations: (1) approximating
                  full-precision weights with the linear combination of multiple
                  binary weight bases; (2) employing multiple binary activations
                  to alleviate information loss. The implementation of the
                  resulting binary CNN, denoted as ABC-Net, is shown to achieve
                  much closer performance to its full-precision counterpart, and
                  even reach the comparable prediction accuracy on ImageNet and
                  forest trail datasets, given adequate binary weight bases and
                  activations.},
  archivePrefix ={arXiv},
  eprint =       {1711.11294},
  primaryClass = {cs.LG},
}
@article{MobileNets,
  author =       {Howard, Andrew G. and Zhu, Menglong and Chen, Bo and
                  Kalenichenko, Dmitry and Wang, Weijun and Weyand, Tobias and
                  Andreetto, Marco and Adam, Hartwig},
  title =        {Mobilenets: Efficient Convolutional Neural Networks for Mobile
                  Vision Applications},
  journal =      {CoRR},
  year =         2017,
  url =          {http://arxiv.org/abs/1704.04861v1},
  abstract =     {We present a class of efficient models called MobileNets for
                  mobile and embedded vision applications. MobileNets are based
                  on a streamlined architecture that uses depth-wise separable
                  convolutions to build light weight deep neural networks. We
                  introduce two simple global hyper-parameters that efficiently
                  trade off between latency and accuracy. These hyper-parameters
                  allow the model builder to choose the right sized model for
                  their application based on the constraints of the problem. We
                  present extensive experiments on resource and accuracy
                  tradeoffs and show strong performance compared to other
                  popular models on ImageNet classification. We then demonstrate
                  the effectiveness of MobileNets across a wide range of
                  applications and use cases including object detection,
                  finegrain classification, face attributes and large scale
                  geo-localization.},
  archivePrefix ={arXiv},
  eprint =       {1704.04861},
  primaryClass = {cs.CV},
}
@article{CompressionSurvey,
  author =       {Cheng, Yu and Wang, Duo and Zhou, Pan and Zhang, Tao},
  title =        {A Survey of Model Compression and Acceleration for Deep Neural
                  Networks},
  journal =      {CoRR},
  year =         2017,
  url =          {http://arxiv.org/abs/1710.09282v8},
  abstract =     {Deep convolutional neural networks (CNNs) have recently
                  achieved great success in many visual recognition tasks.
                  However, existing deep neural network models are
                  computationally expensive and memory intensive, hindering
                  their deployment in devices with low memory resources or in
                  applications with strict latency requirements. Therefore, a
                  natural thought is to perform model compression and
                  acceleration in deep networks without significantly decreasing
                  the model performance. During the past few years, tremendous
                  progress has been made in this area. In this paper, we survey
                  the recent advanced techniques for compacting and accelerating
                  CNNs model developed. These techniques are roughly categorized
                  into four schemes: parameter pruning and sharing, low-rank
                  factorization, transferred/compact convolutional filters, and
                  knowledge distillation. Methods of parameter pruning and
                  sharing will be described at the beginning, after that the
                  other techniques will be introduced. For each scheme, we
                  provide insightful analysis regarding the performance, related
                  applications, advantages, and drawbacks etc. Then we will go
                  through a few very recent additional successful methods, for
                  example, dynamic capacity networks and stochastic depths
                  networks. After that, we survey the evaluation matrix, the
                  main datasets used for evaluating the model performance and
                  recent benchmarking efforts. Finally, we conclude this paper,
                  discuss remaining challenges and possible directions on this
                  topic.},
  archivePrefix ={arXiv},
  eprint =       {1710.09282},
  primaryClass = {cs.LG},
}
@article{bfloat16,
  author =       {Tagliavini, Giuseppe and Mach, Stefan and Rossi, Davide and
                  Marongiu, Andrea and Benini, Luca},
  title =        {A Transprecision Floating-Point Platform for Ultra-Low Power
                  Computing},
  journal =      {CoRR},
  year =         2017,
  url =          {http://arxiv.org/abs/1711.10374v1},
  abstract =     {In modern low-power embedded platforms, floating-point (FP)
                  operations emerge as a major contributor to the energy
                  consumption of compute-intensive applications with large
                  dynamic range. Experimental evidence shows that 50 \% of the
                  energy consumed by a core and its data memory is related to FP
                  computations. The adoption of FP formats requiring a lower
                  number of bits is an interesting opportunity to reduce energy
                  consumption, since it allows to simplify the arithmetic
                  circuitry and to reduce the memory bandwidth between memory
                  and registers by enabling vectorization. From a theoretical
                  point of view, the adoption of multiple FP types perfectly
                  fits with the principle of transprecision computing, allowing
                  fine-grained control of approximation while meeting specified
                  constraints on the precision of final results. In this paper
                  we propose an extended FP type system with complete hardware
                  support to enable transprecision computing on low-power
                  embedded processors, including two standard formats (binary32
                  and binary16) and two new formats (binary8 and binary16alt).
                  First, we introduce a software library that enables
                  exploration of FP types by tuning both precision and dynamic
                  range of program variables. Then, we present a methodology to
                  integrate our library with an external tool for precision
                  tuning, and experimental results that highlight the clear
                  benefits of introducing the new formats. Finally, we present
                  the design of a transprecision FP unit capable of handling
                  8-bit and 16-bit operations in addition to standard 32-bit
                  operations. Experimental results on FP-intensive benchmarks
                  show that up to 90 \% of FP operations can be safely scaled
                  down to 8-bit or 16-bit formats. Thanks to precision tuning
                  and vectorization, execution time is decreased by 12 \% and
                  memory accesses are reduced by 27 \% on average, leading to a
                  reduction of energy consumption up to 30 \%.},
  archivePrefix ={arXiv},
  eprint =       {1711.10374},
  primaryClass = {cs.AR},
}
@article{BinarizedNeuralNetworks,
  author =       {Courbariaux, Matthieu and Hubara, Itay and Soudry, Daniel and
                  El-Yaniv, Ran and Bengio, Yoshua},
  title =        {Binarized Neural Networks: Training Deep Neural Networks With
                  Weights and Activations Constrained To +1 Or -1},
  journal =      {CoRR},
  year =         2016,
  url =          {http://arxiv.org/abs/1602.02830v3},
  abstract =     {We introduce a method to train Binarized Neural Networks
                  (BNNs) - neural networks with binary weights and activations
                  at run-time. At training-time the binary weights and
                  activations are used for computing the parameters gradients.
                  During the forward pass, BNNs drastically reduce memory size
                  and accesses, and replace most arithmetic operations with
                  bit-wise operations, which is expected to substantially
                  improve power-efficiency. To validate the effectiveness of
                  BNNs we conduct two sets of experiments on the Torch7 and
                  Theano frameworks. On both, BNNs achieved nearly
                  state-of-the-art results over the MNIST, CIFAR-10 and SVHN
                  datasets. Last but not least, we wrote a binary matrix
                  multiplication GPU kernel with which it is possible to run our
                  MNIST BNN 7 times faster than with an unoptimized GPU kernel,
                  without suffering any loss in classification accuracy. The
                  code for training and running our BNNs is available on-line.},
  archivePrefix ={arXiv},
  eprint =       {1602.02830},
  primaryClass = {cs.LG},
}
@article{FluxJL,
  author    = {Mike Innes},
  title     = {Flux: Elegant Machine Learning with Julia},
  journal   = {Journal of Open Source Software},
  year      = {2018},
  doi       = {10.21105/joss.00602},
}
@ARTICLE{CUDAnativeJL,
author={T. {Besard} and C. {Foket} and B. {De Sutter}},
journal={IEEE Transactions on Parallel and Distributed Systems},
title={Effective Extensible Programming: Unleashing Julia on GPUs},
year={2019},
volume={30},
number={4},
pages={827-841},
keywords={graphics processing units;high level languages;parallel architectures;parallel programming;program compilers;application code;high-level Julia programming language;GPU programming;application performance;effective extensible programming;accelerators;popular devices;parallelizable applications;efficient device code;low-level programming language;high-level language ecosystem;compiler infrastructure;existing programming language;NVIDIA GPUs;NVIDIA CUDA toolkit;Graphics processing units;Programming;Hardware;High level languages;Libraries;Graphics processors;very high-level languages;code generation;retargetable compilers},
doi={10.1109/TPDS.2018.2872064},
ISSN={},
month={April},}
@article{QuantFriendlyMobileNet,
  author =       {Sheng, Tao and Feng, Chen and Zhuo, Shaojie and Zhang,
                  Xiaopeng and Shen, Liang and Aleksic, Mickey},
  title =        {A Quantization-Friendly Separable Convolution for Mobilenets},
  journal =      {CoRR},
  year =         2018,
  url =          {http://arxiv.org/abs/1803.08607v3},
  abstract =     {As deep learning (DL) is being rapidly pushed to edge
                  computing, researchers invented various ways to make inference
                  computation more efficient on mobile/IoT devices, such as
                  network pruning, parameter compression, and etc. Quantization,
                  as one of the key approaches, can effectively offload GPU, and
                  make it possible to deploy DL on fixed-point pipeline.
                  Unfortunately, not all existing networks design are friendly
                  to quantization. For example, the popular lightweight
                  MobileNetV1, while it successfully reduces parameter size and
                  computation latency with separable convolution, our experiment
                  shows its quantized models have large accuracy gap against its
                  float point models. To resolve this, we analyzed the root
                  cause of quantization loss and proposed a
                  quantization-friendly separable convolution architecture. By
                  evaluating the image classification task on ImageNet2012
                  dataset, our modified MobileNetV1 model can archive 8-bit
                  inference top-1 accuracy in 68.03 \%, almost closed the gap to
                  the float pipeline.},
  archivePrefix ={arXiv},
  eprint =       {1803.08607v3},
  primaryClass = {cs.CV},
}
